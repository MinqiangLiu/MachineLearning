{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minqliu\\AppData\\Local\\Temp\\ipykernel_14820\\3094950062.py:72: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  out[n, oc, i, j] = np.sum(region * kernel[oc]) + bias[oc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/2000], Loss = 3.403006\n",
      "Epoch [400/2000], Loss = 1.091970\n",
      "Epoch [600/2000], Loss = 0.660530\n",
      "Epoch [800/2000], Loss = 0.669164\n",
      "Epoch [1000/2000], Loss = 0.700347\n",
      "Epoch [1200/2000], Loss = 0.697723\n",
      "Epoch [1400/2000], Loss = 0.629579\n",
      "Epoch [1600/2000], Loss = 0.613865\n",
      "Epoch [1800/2000], Loss = 0.507784\n",
      "Epoch [2000/2000], Loss = 0.435224\n",
      "\n",
      "训练完成后最终Loss: 0.435224\n",
      "Sample[0]: True=11.072, Pred=11.638\n",
      "Sample[1]: True=11.341, Pred=11.967\n",
      "Sample[2]: True=12.982, Pred=12.960\n",
      "Sample[3]: True=11.804, Pred=12.544\n",
      "Sample[4]: True=12.575, Pred=13.539\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ============ 1. 生成随机数据 ============\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 100              # 样本数\n",
    "C_in = 1             # 输入通道数（示例中为灰度图）\n",
    "H, W = 5, 5          # 图像高和宽\n",
    "out_channels = 1     # 卷积层输出通道数（示例只用1个通道）\n",
    "kernel_size = 3      # 卷积核的高和宽(3x3)\n",
    "hidden_dim_fc = 1    # 全连接输出维度=1（做回归）\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 2000\n",
    "\n",
    "# 数据 X 形状 (N, C_in, H, W) = (100,1,5,5)\n",
    "X = np.random.rand(N, C_in, H, W)\n",
    "\n",
    "# 目标值 y 形状 (N, 1)，这里做一个简单的回归\n",
    "# 例如让 y = 所有像素之和 + 一点噪声\n",
    "y = np.sum(X, axis=(1,2,3)).reshape(N,1) + 0.1*np.random.randn(N,1)\n",
    "\n",
    "\n",
    "# ============ 2. 初始化参数 ============\n",
    "# 卷积核形状: (out_channels, C_in, kernel_size, kernel_size)\n",
    "# 这里 out_channels=1, C_in=1, kernel_size=3 => (1,1,3,3)\n",
    "conv_kernel = 0.1 * np.random.randn(out_channels, C_in, kernel_size, kernel_size)\n",
    "conv_bias   = np.zeros((out_channels, 1))  # 每个输出通道有1个偏置\n",
    "\n",
    "# 全连接层参数:\n",
    "# 假设卷积输出大小= (out_channels, (H - kernel_size+1), (W - kernel_size+1))\n",
    "# 这里= (1, 3, 3) => flatten后 1*3*3=9\n",
    "fc_in_dim = out_channels * (H - kernel_size + 1) * (W - kernel_size + 1)  # 9\n",
    "fc_W = 0.1 * np.random.randn(fc_in_dim, hidden_dim_fc)  # (9,1)\n",
    "fc_b = np.zeros((1, hidden_dim_fc))                    # (1,1)\n",
    "\n",
    "\n",
    "# ============ 3. 定义辅助函数 ============\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    # x>0 => 1, x<=0 => 0\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def mean_squared_error(pred, true):\n",
    "    return np.mean((pred - true)**2)\n",
    "\n",
    "# 卷积的前向 + 反向（简化版本, stride=1, no padding, single out_channel）\n",
    "def conv2d_forward(X, kernel, bias):\n",
    "    \"\"\"\n",
    "    X.shape: (N, C_in, H, W)\n",
    "    kernel.shape: (out_channels, C_in, kH, kW)\n",
    "    bias.shape: (out_channels, 1)\n",
    "    返回 (N, out_channels, H_out, W_out)\n",
    "    其中 H_out = H - kH + 1, W_out = W - kW + 1\n",
    "    \"\"\"\n",
    "    N, C_in, H, W = X.shape\n",
    "    out_channels, _, kH, kW = kernel.shape\n",
    "    H_out = H - kH + 1\n",
    "    W_out = W - kW + 1\n",
    "\n",
    "    out = np.zeros((N, out_channels, H_out, W_out))\n",
    "    for n in range(N):\n",
    "        for oc in range(out_channels):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    # 取出 X 在 (i : i+kH, j : j+kW) 的局部区域\n",
    "                    region = X[n, :, i:i+kH, j:j+kW]  # shape (C_in,kH,kW)\n",
    "                    # kernel[oc, :, :, :] shape (C_in,kH,kW)\n",
    "                    out[n, oc, i, j] = np.sum(region * kernel[oc]) + bias[oc]\n",
    "    return out\n",
    "\n",
    "def conv2d_backward(dout, X, kernel):\n",
    "    \"\"\"\n",
    "    计算对 X 和 kernel 的梯度 (简化实现):\n",
    "    dout.shape = (N, out_channels, H_out, W_out)\n",
    "    X.shape     = (N, C_in, H, W)\n",
    "    kernel.shape= (out_channels, C_in, kH, kW)\n",
    "    返回:\n",
    "        dX, dKernel, dBias\n",
    "    \"\"\"\n",
    "    N, C_in, H, W = X.shape\n",
    "    out_channels, _, kH, kW = kernel.shape\n",
    "    _, _, H_out, W_out = dout.shape\n",
    "\n",
    "    dX = np.zeros_like(X)\n",
    "    dKernel = np.zeros_like(kernel)\n",
    "    dBias = np.zeros((out_channels, 1))\n",
    "\n",
    "    for n in range(N):\n",
    "        for oc in range(out_channels):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    val = dout[n, oc, i, j]\n",
    "                    # 对 bias\n",
    "                    dBias[oc] += val\n",
    "                    # 对 kernel\n",
    "                    region = X[n, :, i:i+kH, j:j+kW]  # (C_in,kH,kW)\n",
    "                    dKernel[oc] += region * val\n",
    "                    # 对 X\n",
    "                    dX[n, :, i:i+kH, j:j+kW] += kernel[oc] * val\n",
    "\n",
    "    return dX, dKernel, dBias\n",
    "\n",
    "\n",
    "# ============ 4. 训练循环 ============\n",
    "loss_history = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # ---- (1) 前向传播 ----\n",
    "    # 1) 卷积层\n",
    "    conv_out = conv2d_forward(X, conv_kernel, conv_bias)  # (N,1,3,3)\n",
    "\n",
    "    # 2) ReLU\n",
    "    relu_out = relu(conv_out)  # (N,1,3,3)\n",
    "\n",
    "    # 3) Flatten\n",
    "    # 先把 (N,1,3,3) 拉平到 (N, 9)\n",
    "    N_, oc_, h_, w_ = relu_out.shape\n",
    "    flatten_out = relu_out.reshape(N_, -1)  # (N, 9)\n",
    "\n",
    "    # 4) 全连接层\n",
    "    # (N,9) x (9,1) => (N,1)\n",
    "    fc_out = flatten_out.dot(fc_W) + fc_b  # (N,1)\n",
    "\n",
    "    # 5) 计算损失 (MSE)\n",
    "    loss = mean_squared_error(fc_out, y)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "    # ---- (2) 反向传播 ----\n",
    "    # dL/d(fc_out)\n",
    "    dL_dfc_out = 2*(fc_out - y) / N  # shape (N,1)\n",
    "\n",
    "    # 1) 全连接层反向\n",
    "    # fc_out = flatten_out.dot(fc_W) + fc_b\n",
    "    d_fc_W = flatten_out.T.dot(dL_dfc_out)  # (9,N) x (N,1)->(9,1)\n",
    "    d_fc_b = np.sum(dL_dfc_out, axis=0, keepdims=True)  # (1,1)\n",
    "\n",
    "    d_flatten_out = dL_dfc_out.dot(fc_W.T)  # (N,1) x (1,9)->(N,9)\n",
    "\n",
    "    # 2) Flatten层反向 -> ReLU输出\n",
    "    d_relu_out = d_flatten_out.reshape(N_, oc_, h_, w_)  # (N,1,3,3)\n",
    "\n",
    "    # 3) ReLU 反向\n",
    "    # relu_out = relu(conv_out)\n",
    "    d_conv_out = d_relu_out * relu_deriv(conv_out)  # (N,1,3,3)\n",
    "\n",
    "    # 4) 卷积层反向\n",
    "    dX, dKernel, dBias = conv2d_backward(d_conv_out, X, conv_kernel)\n",
    "\n",
    "    # ---- (3) 参数更新 ----\n",
    "    conv_kernel -= learning_rate * dKernel\n",
    "    conv_bias   -= learning_rate * dBias\n",
    "    fc_W        -= learning_rate * d_fc_W\n",
    "    fc_b        -= learning_rate * d_fc_b\n",
    "\n",
    "    # ---- (4) 打印训练过程 ----\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss = {loss:.6f}\")\n",
    "\n",
    "# ============ 5. 查看结果 ============\n",
    "print(\"\\n训练完成后最终Loss: {:.6f}\".format(loss_history[-1]))\n",
    "# 随机挑几条样本看看预测\n",
    "test_indices = [0,1,2,3,4]\n",
    "pred = fc_out  # 最后一轮的前向传播结果\n",
    "for i in test_indices:\n",
    "    print(f\"Sample[{i}]: True={y[i][0]:.3f}, Pred={pred[i][0]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

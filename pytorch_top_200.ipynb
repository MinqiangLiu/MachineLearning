{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# PyTorch 常用方法示例 (Top 200)\n",
				"本 Notebook 展示了约 200 个 **PyTorch** 常用方法或功能的简要示例。每个示例位于一个单独单元格中。\n",
				"\n",
				"**使用说明：**\n",
				"- 请确保已安装 PyTorch (例如 `pip install torch`)，并能在 Python 环境中导入；\n",
				"- 大部分示例以 `import torch` 为基础；\n",
				"- 示例只示范最基本用法，更多高级功能请参阅官方文档；\n",
				"- 在执行前确保在 Jupyter 中或支持 IPython 的环境运行。"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 931,
			"id": "cf9b9225",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"PyTorch version: 2.5.1+cpu\n"
					]
				}
			],
			"source": [
				"# 1. 导入与版本查看\n",
				"import torch\n",
				"print(\"PyTorch version:\", torch.__version__)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 932,
			"id": "544dae9b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1., 2., 3.])\n"
					]
				}
			],
			"source": [
				"# 2. 创建张量: torch.tensor\n",
				"x = torch.tensor([1,2,3], dtype=torch.float32)\n",
				"print(x)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 933,
			"id": "c64cf6ca",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([3]) torch.float32 cpu\n"
					]
				}
			],
			"source": [
				"# 3. 张量属性: shape, dtype, device\n",
				"print(x.shape, x.dtype, x.device)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 934,
			"id": "03660a98",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"CUDA not available\n"
					]
				}
			],
			"source": [
				"# 4. 张量移动到GPU (如果可用)\n",
				"if torch.cuda.is_available():\n",
				"    x_gpu = x.to('cuda')\n",
				"    print(x_gpu.device)\n",
				"else:\n",
				"    print(\"CUDA not available\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 935,
			"id": "ecb5857c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[ 0.1378, -0.6330, -1.2384],\n",
						"        [ 0.3924, -0.2469,  1.0956]])\n"
					]
				}
			],
			"source": [
				"# 5. 创建随机张量: torch.randn\n",
				"rand_t = torch.randn(2,3)\n",
				"print(rand_t)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 936,
			"id": "c76582a8",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[0.0443, 0.6136],\n",
						"        [0.6443, 0.3045]])\n"
					]
				}
			],
			"source": [
				"# 6. 创建随机张量: torch.rand, 范围 [0,1)\n",
				"rand_01 = torch.rand(2,2)\n",
				"print(rand_01)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 937,
			"id": "a66ddedc",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[2, 1, 0],\n",
						"        [4, 1, 0],\n",
						"        [2, 3, 1]])\n"
					]
				}
			],
			"source": [
				"# 7. 创建整型随机张量: torch.randint\n",
				"rand_int = torch.randint(low=0, high=5, size=(3,3))\n",
				"print(rand_int)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 938,
			"id": "d680ef4a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[0., 0., 0.],\n",
						"        [0., 0., 0.]])\n",
						"tensor([[1., 1., 1.],\n",
						"        [1., 1., 1.]])\n",
						"tensor([[7, 7, 7],\n",
						"        [7, 7, 7]])\n"
					]
				}
			],
			"source": [
				"# 8. 创建全0，全1或全特定值的张量: torch.zeros, torch.ones, torch.full\n",
				"z = torch.zeros(2,3)\n",
				"o = torch.ones(2,3)\n",
				"f = torch.full((2,3), 7)\n",
				"print(z, o, f, sep='\\n')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 939,
			"id": "0a0d85e0",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[1., 0., 0.],\n",
						"        [0., 1., 0.],\n",
						"        [0., 0., 1.]])\n"
					]
				}
			],
			"source": [
				"# 9. 单位矩阵: torch.eye\n",
				"eye_ = torch.eye(3)\n",
				"print(eye_)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 940,
			"id": "a836d02c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0., 0., 0.]) tensor([1., 1., 1.])\n"
					]
				}
			],
			"source": [
				"# 10. 创建与某张量形状相同的全0,全1: torch.zeros_like, torch.ones_like\n",
				"like_zeros = torch.zeros_like(x)\n",
				"like_ones = torch.ones_like(x)\n",
				"print(like_zeros, like_ones)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 941,
			"id": "a43f694b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0, 1, 2, 3, 4])\n",
						"tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
					]
				}
			],
			"source": [
				"# 11. torch.arange / torch.linspace\n",
				"ar = torch.arange(0,5, step=1)\n",
				"lin = torch.linspace(0,1, steps=5)\n",
				"print(ar)\n",
				"print(lin)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 942,
			"id": "3357d3ca",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[1, 2],\n",
						"        [3, 4],\n",
						"        [5, 6]])\n",
						"tensor([1, 2, 3, 4, 5, 6])\n"
					]
				}
			],
			"source": [
				"# 12. 张量的形状变换: .view or .reshape\n",
				"y = torch.tensor([[1,2,3],[4,5,6]])\n",
				"y_reshaped = y.view(3,2)\n",
				"print(y_reshaped)\n",
				"print(y.reshape(-1))  # 拉平"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 943,
			"id": "1976e412",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[1, 4],\n",
						"        [2, 5],\n",
						"        [3, 6]])\n"
					]
				}
			],
			"source": [
				"# 13. 张量维度变换: torch.transpose or .t()\n",
				"y_trans = y.t()\n",
				"print(y_trans)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 944,
			"id": "ab586e0b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([3, 1]) torch.Size([3])\n"
					]
				}
			],
			"source": [
				"# 14. 改变维度：unsqueeze / squeeze\n",
				"a = torch.tensor([1,2,3])\n",
				"a_unsq = a.unsqueeze(1)\n",
				"a_sq = a_unsq.squeeze(1)\n",
				"print(a_unsq.size(), a_sq.size())"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 945,
			"id": "467144ab",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([4, 2]) torch.Size([2, 4])\n"
					]
				}
			],
			"source": [
				"# 15. 拼接: torch.cat\n",
				"t1 = torch.randn(2,2)\n",
				"t2 = torch.randn(2,2)\n",
				"cat_dim0 = torch.cat((t1, t2), dim=0)\n",
				"cat_dim1 = torch.cat((t1, t2), dim=1)\n",
				"print(cat_dim0.shape, cat_dim1.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 946,
			"id": "5f45b2ef",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 2, 2])\n"
					]
				}
			],
			"source": [
				"# 16. 堆叠: torch.stack\n",
				"stacked = torch.stack([t1, t2], dim=0)\n",
				"print(stacked.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 947,
			"id": "456c3f05",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1, 2, 1, 2, 1, 2])\n",
						"tensor([[1, 2, 1, 2, 1, 2],\n",
						"        [3, 4, 3, 4, 3, 4],\n",
						"        [1, 2, 1, 2, 1, 2],\n",
						"        [3, 4, 3, 4, 3, 4]])\n"
					]
				}
			],
			"source": [
				"# 17. 复制扩展: torch.repeat\n",
				"r = torch.tensor([1,2]).repeat(3)\n",
				"print(r)\n",
				"r2d = torch.tensor([[1,2],[3,4]]).repeat(2,3)\n",
				"print(r2d)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 948,
			"id": "4d516519",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1, 2])\n",
						"tensor([[5, 6],\n",
						"        [8, 9]])\n"
					]
				}
			],
			"source": [
				"# 18. 索引: 直接用 Python 切片\n",
				"mat = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
				"print(mat[0, :2])\n",
				"print(mat[1:, 1:])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 949,
			"id": "5990e62e",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[1, 2, 3],\n",
						"        [7, 8, 9]])\n"
					]
				}
			],
			"source": [
				"# 19. 高级索引: index_select, gather\n",
				"idx = torch.tensor([0,2])\n",
				"sel = torch.index_select(mat, dim=0, index=idx)\n",
				"print(sel)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 950,
			"id": "89984fa8",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[3, 2, 1],\n",
						"        [4, 6, 5],\n",
						"        [8, 7, 9]])\n"
					]
				}
			],
			"source": [
				"# 20. gather\n",
				"vals = torch.gather(mat, dim=1, index=torch.tensor([[2,1,0],[0,2,1],[1,0,2]]))\n",
				"print(vals)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 951,
			"id": "645f4808",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([6, 7, 8, 9])\n"
					]
				}
			],
			"source": [
				"# 21. boolean mask 索引\n",
				"mask = (mat > 5)\n",
				"print(mat[mask])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 952,
			"id": "0a62313b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[9, 9, 9],\n",
						"        [8, 8, 8],\n",
						"        [7, 7, 7]])\n"
					]
				}
			],
			"source": [
				"# 22. scatter_ 用于原地写入\n",
				"src = torch.tensor([[9,9,9],[8,8,8],[7,7,7]])\n",
				"index = torch.tensor([[2,1,0],[0,2,1],[1,0,2]])\n",
				"mat_scatter = mat.clone()\n",
				"mat_scatter.scatter_(dim=1, index=index, src=src)\n",
				"print(mat_scatter)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 953,
			"id": "159cd82d",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([ 1.5153, -2.3079,  0.7093])\n",
						"tensor([-0.6546, -0.2006,  0.0210])\n",
						"tensor([0.4669, 1.3216, 0.1257])\n",
						"tensor([0.3967, 1.1904, 1.0611])\n"
					]
				}
			],
			"source": [
				"# 23. 张量加减乘除: +, -, *, /\n",
				"a = torch.randn(3)\n",
				"b = torch.randn(3)\n",
				"print(a + b)\n",
				"print(a - b)\n",
				"print(a * b)\n",
				"print(a / b)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 954,
			"id": "8308c09c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([ 1.5153, -2.3079,  0.7093])\n",
						"tensor([0.4669, 1.3216, 0.1257])\n"
					]
				}
			],
			"source": [
				"# 24. torch.add, torch.sub, torch.mul, torch.div\n",
				"print(torch.add(a, b))\n",
				"print(torch.mul(a, b))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 955,
			"id": "d6a2e383",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 4])\n"
					]
				}
			],
			"source": [
				"# 25. 矩阵乘法: @ 或 torch.matmul\n",
				"m1 = torch.randn(2,3)\n",
				"m2 = torch.randn(3,4)\n",
				"out_matmul = m1 @ m2\n",
				"print(out_matmul.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 956,
			"id": "85b867ea",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 4])\n",
						"torch.Size([10, 2, 4])\n"
					]
				}
			],
			"source": [
				"# 26. torch.mm, torch.bmm (batch)\n",
				"mm_res = torch.mm(m1, m2)\n",
				"print(mm_res.shape)\n",
				"\n",
				"b1 = torch.randn(10,2,3)\n",
				"b2 = torch.randn(10,3,4)\n",
				"bmm_res = torch.bmm(b1, b2)\n",
				"print(bmm_res.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 957,
			"id": "911201c8",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(-2.6119)\n",
						"tensor(-0.6530)\n",
						"tensor(0.4325)\n",
						"tensor(-1.4226)\n"
					]
				}
			],
			"source": [
				"# 27. 求和 / 均值 / 最大最小: torch.sum, torch.mean, torch.max, torch.min\n",
				"vals_2d = torch.randn(2,2)\n",
				"print(torch.sum(vals_2d))\n",
				"print(torch.mean(vals_2d))\n",
				"print(torch.max(vals_2d))\n",
				"print(torch.min(vals_2d))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 958,
			"id": "74bc0d8e",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-2.4384, -0.1735])\n",
						"tensor([-1.0143, -0.2917])\n"
					]
				}
			],
			"source": [
				"# 28. 沿维度求值: dim 参数\n",
				"print(torch.sum(vals_2d, dim=0))\n",
				"print(torch.mean(vals_2d, dim=1))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 959,
			"id": "884d9431",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([ 0.2387,  1.7671, -2.9892,  0.9902, -2.1977])\n",
						"tensor(1) tensor(2)\n"
					]
				}
			],
			"source": [
				"# 29. torch.argmax / torch.argmin\n",
				"r = torch.randn(5)\n",
				"print(r)\n",
				"print(torch.argmax(r), torch.argmin(r))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 960,
			"id": "f5f66a26",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([False, False, False]) tensor([False, False,  True])\n"
					]
				}
			],
			"source": [
				"# 30. 比较运算: torch.eq, torch.gt, torch.lt\n",
				"cmp_eq = torch.eq(a, b)\n",
				"cmp_gt = torch.gt(a, b)\n",
				"print(cmp_eq, cmp_gt)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 961,
			"id": "ebc2a6c8",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0.0000, 0.5000, 2.0000, 2.0000])\n"
					]
				}
			],
			"source": [
				"# 31. clamp (类似clip)\n",
				"randvals = torch.tensor([-1.0,0.5,3.0,5.0])\n",
				"cl = torch.clamp(randvals, min=0.0, max=2.0)\n",
				"print(cl)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 962,
			"id": "4eb901a7",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.return_types.sort(\n",
						"values=tensor([-2.9892, -2.1977,  0.2387,  0.9902,  1.7671]),\n",
						"indices=tensor([2, 4, 0, 3, 1]))\n",
						"torch.return_types.topk(\n",
						"values=tensor([1.7671, 0.9902]),\n",
						"indices=tensor([1, 3]))\n"
					]
				}
			],
			"source": [
				"# 32. 排序: torch.sort / torch.topk\n",
				"srt_res = torch.sort(r)\n",
				"top2 = torch.topk(r, k=2)\n",
				"print(srt_res)\n",
				"print(top2)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 963,
			"id": "e4466019",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-0.6060,  0.4325]) tensor([1, 1])\n"
					]
				}
			],
			"source": [
				"# 33. index of max / min: torch.argmax already shown, also torch.max can return indices\n",
				"vals, idxs = torch.max(vals_2d, dim=1)\n",
				"print(vals, idxs)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 964,
			"id": "6dac155c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1.2000, 0.3000, 2.7000])\n",
						"tensor([-1.,  1.,  3.])\n",
						"tensor([-2.,  0.,  2.])\n"
					]
				}
			],
			"source": [
				"# 34. torch.abs / torch.ceil / torch.floor\n",
				"vals_pm = torch.tensor([-1.2, 0.3, 2.7])\n",
				"print(torch.abs(vals_pm))\n",
				"print(torch.ceil(vals_pm))\n",
				"print(torch.floor(vals_pm))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 965,
			"id": "268019a2",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-1.,  0.,  3.])\n",
						"tensor([-1.,  0.,  2.])\n",
						"tensor([-0.2000,  0.3000,  0.7000])\n"
					]
				}
			],
			"source": [
				"# 35. torch.round / torch.trunc / torch.frac\n",
				"print(torch.round(vals_pm))\n",
				"print(torch.trunc(vals_pm))\n",
				"print(torch.frac(vals_pm))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 966,
			"id": "57b8baf3",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([4., 9.]) tensor([2., 3.]) tensor([2.7183]) tensor([1.0000])\n"
					]
				}
			],
			"source": [
				"# 36. 幂函数与log: torch.pow, torch.sqrt, torch.exp, torch.log\n",
				"p = torch.pow(torch.tensor([2.0,3.0]), 2)\n",
				"sq = torch.sqrt(torch.tensor([4.0,9.0]))\n",
				"ex = torch.exp(torch.tensor([1.0]))\n",
				"lg = torch.log(torch.tensor([2.7183]))\n",
				"print(p, sq, ex, lg)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 967,
			"id": "a77993fd",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0.0000e+00, 1.0000e+00, 2.5352e-06])\n",
						"tensor([ 1.0000e+00,  1.2676e-06, -1.0000e+00])\n"
					]
				}
			],
			"source": [
				"# 37. 三角函数: torch.sin, torch.cos, torch.tan\n",
				"vals_trig = torch.tensor([0.0, 3.14159/2, 3.14159])\n",
				"print(torch.sin(vals_trig))\n",
				"print(torch.cos(vals_trig))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 968,
			"id": "493a0e07",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[ 0.6667, -0.3333],\n",
						"        [-0.3333,  0.6667]]) tensor(3.)\n"
					]
				}
			],
			"source": [
				"# 38. 矩阵操作: torch.inverse, torch.det\n",
				"mat2x2 = torch.tensor([[2.0,1.0],[1.0,2.0]])\n",
				"inv_m = torch.inverse(mat2x2)\n",
				"det_m = torch.det(mat2x2)\n",
				"print(inv_m, det_m)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 969,
			"id": "61f37c3a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(4.)\n"
					]
				}
			],
			"source": [
				"# 39. torch.trace\n",
				"tr = torch.trace(mat2x2)\n",
				"print(tr)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 970,
			"id": "03c58c40",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[11, 21, 31],\n",
						"        [12, 22, 32],\n",
						"        [13, 23, 33]])\n"
					]
				}
			],
			"source": [
				"# 40. 广播机制\n",
				"br_a = torch.tensor([[1],[2],[3]])\n",
				"br_b = torch.tensor([10,20,30])\n",
				"br_res = br_a + br_b  # shape(3,3)\n",
				"print(br_res)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 971,
			"id": "ac7e5987",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(-0.1064) tensor([-0.4501,  0.1661,  0.1770, -0.3184])\n"
					]
				}
			],
			"source": [
				"# 41. torch.mean/tensor.mean, 指定维度\n",
				"val_2d = torch.randn(3,4)\n",
				"mean_all = val_2d.mean()\n",
				"mean_dim0 = val_2d.mean(dim=0)\n",
				"print(mean_all, mean_dim0)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 972,
			"id": "18705c2e",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([3, 1])\n"
					]
				}
			],
			"source": [
				"# 42. keepdim 参数\n",
				"mean_dim1_keep = val_2d.mean(dim=1, keepdim=True)\n",
				"print(mean_dim1_keep.size())"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 973,
			"id": "2d3e1d66",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"10 <class 'int'>\n"
					]
				}
			],
			"source": [
				"# 43. .item() 将单元素张量转换为Python数值\n",
				"single_val = torch.tensor([10])\n",
				"python_val = single_val.item()\n",
				"print(python_val, type(python_val))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 974,
			"id": "2c8ecb26",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.int64 torch.float64\n"
					]
				}
			],
			"source": [
				"# 44. 类型转换: .float(), .long(), .int(), .double()\n",
				"val_long = single_val.long()\n",
				"val_double = single_val.double()\n",
				"print(val_long.dtype, val_double.dtype)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 975,
			"id": "e3192784",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"False\n"
					]
				}
			],
			"source": [
				"# 45. detach() 分离梯度\n",
				"x_req_grad = torch.tensor(1.0, requires_grad=True)\n",
				"y_no_grad = x_req_grad.detach()\n",
				"print(y_no_grad.requires_grad)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 976,
			"id": "155ecb73",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"True\n"
					]
				}
			],
			"source": [
				"# 46. requires_grad\n",
				"w = torch.tensor([1.0,2.0,3.0], requires_grad=True)\n",
				"print(w.requires_grad)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 977,
			"id": "78844e7f",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1., 1., 1.])\n"
					]
				}
			],
			"source": [
				"# 47. 自动求梯度: .backward()\n",
				"scaler = w.sum()  # = 6\n",
				"scaler.backward()  # d(scaler)/dw = [1,1,1]\n",
				"print(w.grad)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 978,
			"id": "fa93d5cd",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0., 0., 0.])\n"
					]
				}
			],
			"source": [
				"# 48. grad 清零: .grad.zero_()\n",
				"w.grad.zero_()\n",
				"print(w.grad)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 979,
			"id": "4bfa9983",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"False\n"
					]
				}
			],
			"source": [
				"# 49. with torch.no_grad(): 阻断梯度追踪\n",
				"with torch.no_grad():\n",
				"    y_ng = w * 2\n",
				"print(y_ng.requires_grad)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 980,
			"id": "bf03bda5",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(14.)\n"
					]
				}
			],
			"source": [
				"# 50. 自定义函数 + autograd\n",
				"x_var = torch.tensor(2.0, requires_grad=True)\n",
				"y_var = 3*x_var**2 + 2*x_var + 1\n",
				"y_var.backward()\n",
				"print(x_var.grad)  # dy/dx=6x+2 => x=2 => 6*2+2=14"
			]
		},
		{
			"cell_type": "markdown",
			"id": "fc1097c3",
			"metadata": {},
			"source": [
				"## 神经网络 (torch.nn) 部分"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 981,
			"id": "35e89e01",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 3])\n"
					]
				}
			],
			"source": [
				"# 51. nn.Linear\n",
				"import torch.nn as nn\n",
				"\n",
				"linear = nn.Linear(in_features=4, out_features=3)\n",
				"inp_data = torch.randn(2,4)\n",
				"out_data = linear(inp_data)\n",
				"print(out_data.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 982,
			"id": "45608d09",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0.0000, 0.5000, 2.0000])\n"
					]
				}
			],
			"source": [
				"# 52. nn.ReLU\n",
				"relu_fn = nn.ReLU()\n",
				"vals_r = torch.tensor([-1.0,0.5,2.0])\n",
				"out_relu = relu_fn(vals_r)\n",
				"print(out_relu)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 983,
			"id": "8786637e",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([5, 2])\n"
					]
				}
			],
			"source": [
				"# 53. nn.Sequential\n",
				"model_seq = nn.Sequential(\n",
				"    nn.Linear(4,8),\n",
				"    nn.ReLU(),\n",
				"    nn.Linear(8,2)\n",
				")\n",
				"sample_in = torch.randn(5,4)\n",
				"model_out = model_seq(sample_in)\n",
				"print(model_out.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 984,
			"id": "f490889a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"MyNet(\n",
						"  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
						"  (relu): ReLU()\n",
						"  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
						")\n"
					]
				}
			],
			"source": [
				"# 54. 自定义nn.Module\n",
				"class MyNet(nn.Module):\n",
				"    def __init__(self, in_dim, hidden_dim, out_dim):\n",
				"        super().__init__()\n",
				"        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
				"        self.relu = nn.ReLU()\n",
				"        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
				"    def forward(self, x):\n",
				"        x = self.fc1(x)\n",
				"        x = self.relu(x)\n",
				"        x = self.fc2(x)\n",
				"        return x\n",
				"\n",
				"net = MyNet(4,8,2)\n",
				"print(net)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 985,
			"id": "af1e1c76",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([5, 2])\n"
					]
				}
			],
			"source": [
				"# 55. forward\n",
				"out_cust = net(sample_in)\n",
				"print(out_cust.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 986,
			"id": "d9c7545c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 6, 32, 32])\n"
					]
				}
			],
			"source": [
				"# 56. nn.Conv2d\n",
				"conv2d = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, padding=1)\n",
				"img_ = torch.randn(2,3,32,32)\n",
				"img_out = conv2d(img_)\n",
				"print(img_out.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 987,
			"id": "2d498a82",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 6, 16, 16])\n"
					]
				}
			],
			"source": [
				"# 57. nn.MaxPool2d\n",
				"pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
				"pooled = pool2d(img_out)\n",
				"print(pooled.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 988,
			"id": "490b105f",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 1536])\n"
					]
				}
			],
			"source": [
				"# 58. nn.Flatten\n",
				"flat = nn.Flatten()\n",
				"flat_out = flat(pooled)\n",
				"print(flat_out.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 989,
			"id": "c10995ba",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 1536])\n"
					]
				}
			],
			"source": [
				"# 59. nn.Dropout\n",
				"drop = nn.Dropout(p=0.5)\n",
				"drop_out = drop(flat_out)\n",
				"print(drop_out.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 990,
			"id": "9855ce9b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 6, 32, 32])\n"
					]
				}
			],
			"source": [
				"# 60. nn.BatchNorm2d\n",
				"bn2d = nn.BatchNorm2d(num_features=6)\n",
				"bn_out = bn2d(img_out)\n",
				"print(bn_out.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 991,
			"id": "b51152ee",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 5, 20]) torch.Size([1, 2, 20]) torch.Size([1, 2, 20])\n"
					]
				}
			],
			"source": [
				"# 61. nn.LSTM\n",
				"lstm = nn.LSTM(input_size=10, hidden_size=20, batch_first=True)\n",
				"seq_in = torch.randn(2,5,10)\n",
				"lstm_out, (h_n, c_n) = lstm(seq_in)\n",
				"print(lstm_out.shape, h_n.shape, c_n.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 992,
			"id": "9488dfba",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([3, 7, 16]) torch.Size([1, 3, 16])\n"
					]
				}
			],
			"source": [
				"# 62. nn.GRU\n",
				"gru = nn.GRU(input_size=8, hidden_size=16, batch_first=True)\n",
				"gru_in = torch.randn(3,7,8)\n",
				"gru_out, h_n = gru(gru_in)\n",
				"print(gru_out.shape, h_n.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 993,
			"id": "798fbe59",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([4, 4])\n"
					]
				}
			],
			"source": [
				"# 63. nn.Embedding\n",
				"emb = nn.Embedding(num_embeddings=10, embedding_dim=4)\n",
				"idxs = torch.tensor([1,3,5,9])\n",
				"emb_out = emb(idxs)\n",
				"print(emb_out.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 994,
			"id": "301b449c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[0.0184, 0.1395, 0.1329, 0.3901, 0.3190],\n",
						"        [0.0630, 0.6372, 0.1386, 0.0673, 0.0939]])\n"
					]
				}
			],
			"source": [
				"# 64. nn.functional 常用: F.relu, F.softmax, F.cross_entropy\n",
				"import torch.nn.functional as F\n",
				"logits = torch.randn(2,5)\n",
				"pred_probas = F.softmax(logits, dim=1)\n",
				"print(pred_probas)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 995,
			"id": "f7062825",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0., 2., 0.])\n"
					]
				}
			],
			"source": [
				"# 65. F.relu\n",
				"rel = F.relu(torch.tensor([-1.0, 2.0, -0.5]))\n",
				"print(rel)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 996,
			"id": "cd7ce65b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(1.5427)\n"
					]
				}
			],
			"source": [
				"# 66. F.cross_entropy\n",
				"labels = torch.tensor([1,3])  # batch=2\n",
				"logits_ce = torch.randn(2,5)\n",
				"loss_ce = F.cross_entropy(logits_ce, labels)\n",
				"print(loss_ce)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 997,
			"id": "ad256332",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(0.1450)\n"
					]
				}
			],
			"source": [
				"# 67. nn.MSELoss\n",
				"mse_loss = nn.MSELoss()\n",
				"pred_ = torch.tensor([0.5,0.8])\n",
				"target_ = torch.tensor([1.0,1.0])\n",
				"loss_m = mse_loss(pred_, target_)\n",
				"print(loss_m)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 998,
			"id": "c1912ca1",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(0.2231)\n"
					]
				}
			],
			"source": [
				"# 68. nn.BCELoss / nn.BCEWithLogitsLoss\n",
				"bce_loss_fn = nn.BCELoss()\n",
				"pred_bce = torch.tensor([0.8,0.2])\n",
				"target_bce = torch.tensor([1.0, 0.0])\n",
				"loss_bce = bce_loss_fn(pred_bce, target_bce)\n",
				"print(loss_bce)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 999,
			"id": "f8c493ea",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(0.3377)\n"
					]
				}
			],
			"source": [
				"# 69. BCEWithLogitsLoss\n",
				"bce_logit_loss_fn = nn.BCEWithLogitsLoss()\n",
				"logits_bl = torch.tensor([1.5, -0.5])\n",
				"target_bl = torch.tensor([1.0, 0.0])\n",
				"loss_bl = bce_logit_loss_fn(logits_bl, target_bl)\n",
				"print(loss_bl)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1000,
			"id": "26aa6945",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"SGD (\n",
						"Parameter Group 0\n",
						"    dampening: 0\n",
						"    differentiable: False\n",
						"    foreach: None\n",
						"    fused: None\n",
						"    lr: 0.01\n",
						"    maximize: False\n",
						"    momentum: 0\n",
						"    nesterov: False\n",
						"    weight_decay: 0\n",
						")\n"
					]
				}
			],
			"source": [
				"# 70. 优化器: torch.optim.SGD\n",
				"import torch.optim as optim\n",
				"\n",
				"model = nn.Linear(4,2)\n",
				"optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
				"print(optimizer)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1001,
			"id": "251ac338",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"step done.\n"
					]
				}
			],
			"source": [
				"# 71. optimizer.step(), optimizer.zero_grad()\n",
				"optimizer.zero_grad()\n",
				"fake_input = torch.randn(1,4)\n",
				"fake_target = torch.randn(1,2)\n",
				"output = model(fake_input)\n",
				"loss_ = F.mse_loss(output, fake_target)\n",
				"loss_.backward()\n",
				"optimizer.step()\n",
				"print(\"step done.\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1002,
			"id": "59b67775",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Adam (\n",
						"Parameter Group 0\n",
						"    amsgrad: False\n",
						"    betas: (0.9, 0.999)\n",
						"    capturable: False\n",
						"    differentiable: False\n",
						"    eps: 1e-08\n",
						"    foreach: None\n",
						"    fused: None\n",
						"    lr: 0.001\n",
						"    maximize: False\n",
						"    weight_decay: 0\n",
						")\n"
					]
				}
			],
			"source": [
				"# 72. 其他优化器: Adam\n",
				"adam_opt = optim.Adam(model.parameters(), lr=0.001)\n",
				"print(adam_opt)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1003,
			"id": "ac3be730",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Epoch 0 LR= 0.001\n",
						"Epoch 1 LR= 0.001\n",
						"Epoch 2 LR= 0.001\n"
					]
				}
			],
			"source": [
				"# 73. 学习率调度: optim.lr_scheduler.StepLR\n",
				"scheduler = optim.lr_scheduler.StepLR(adam_opt, step_size=10, gamma=0.1)\n",
				"for epoch in range(3):\n",
				"    # do training...\n",
				"    scheduler.step()\n",
				"    print(\"Epoch\", epoch, \"LR=\", adam_opt.param_groups[0]['lr'])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1004,
			"id": "1fabaabc",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([8, 4]) torch.Size([8])\n"
					]
				}
			],
			"source": [
				"# 74. DataLoader 与 Dataset\n",
				"from torch.utils.data import Dataset, DataLoader\n",
				"\n",
				"class MyDataset(Dataset):\n",
				"    def __init__(self):\n",
				"        self.data = torch.randn(100,4)\n",
				"        self.labels = torch.randint(0,2,(100,))\n",
				"    def __len__(self):\n",
				"        return 100\n",
				"    def __getitem__(self, idx):\n",
				"        return self.data[idx], self.labels[idx]\n",
				"\n",
				"ds = MyDataset()\n",
				"loader = DataLoader(ds, batch_size=8, shuffle=True)\n",
				"for batch_x, batch_y in loader:\n",
				"    print(batch_x.size(), batch_y.size())\n",
				"    break"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1005,
			"id": "83a7cfd7",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"80 20\n"
					]
				}
			],
			"source": [
				"# 75. Dataset random split\n",
				"train_ds, val_ds = torch.utils.data.random_split(ds, [80,20])\n",
				"print(len(train_ds), len(val_ds))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1006,
			"id": "89a35bd9",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 3]) torch.Size([2])\n"
					]
				}
			],
			"source": [
				"# 76. TensorDataset\n",
				"from torch.utils.data import TensorDataset\n",
				"data_t = torch.randn(10,3)\n",
				"label_t = torch.randint(0,2,(10,))\n",
				"ds_t = TensorDataset(data_t, label_t)\n",
				"loader_t = DataLoader(ds_t, batch_size=2)\n",
				"for dx, dy in loader_t:\n",
				"    print(dx.shape, dy.shape)\n",
				"    break"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1007,
			"id": "64634a71",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"100\n"
					]
				}
			],
			"source": [
				"# 77. ConcatDataset\n",
				"ds_concat = torch.utils.data.ConcatDataset([train_ds, val_ds])\n",
				"print(len(ds_concat))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e1ef17e5",
			"metadata": {},
			"source": [
				"## 训练一个简单分类器例子"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1008,
			"id": "4c33af16",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Epoch 0 done.\n",
						"Epoch 1 done.\n"
					]
				}
			],
			"source": [
				"# 78. 简单训练循环 (pseudo-code)\n",
				"net_cls = nn.Sequential(\n",
				"    nn.Linear(4,5),\n",
				"    nn.ReLU(),\n",
				"    nn.Linear(5,2)\n",
				")\n",
				"criterion = nn.CrossEntropyLoss()\n",
				"optim_sgd = optim.SGD(net_cls.parameters(), lr=0.01)\n",
				"\n",
				"for epoch in range(2):\n",
				"    for batch_x, batch_y in loader:\n",
				"        optim_sgd.zero_grad()\n",
				"        pred_ = net_cls(batch_x)\n",
				"        loss_c = criterion(pred_, batch_y)\n",
				"        loss_c.backward()\n",
				"        optim_sgd.step()\n",
				"    print(\"Epoch\", epoch, \"done.\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1009,
			"id": "e04f437a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Validation step example.\n"
					]
				}
			],
			"source": [
				"# 79. 验证\n",
				"net_cls.eval()\n",
				"with torch.no_grad():\n",
				"    for val_x, val_y in loader:\n",
				"        val_pred = net_cls(val_x)\n",
				"        # do something\n",
				"        break\n",
				"print(\"Validation step example.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9a1dbe36",
			"metadata": {},
			"source": [
				"## GPU training"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1010,
			"id": "05e7fa18",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"moved to device.\n"
					]
				}
			],
			"source": [
				"# 80. to(device)\n",
				"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
				"net_cls.to(device)\n",
				"for batch_x, batch_y in loader:\n",
				"    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
				"    # training loop...\n",
				"    break\n",
				"print(\"moved to device.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "825e8cf4",
			"metadata": {},
			"source": [
				"## torch.save / torch.load"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1011,
			"id": "15bb5752",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Loaded model.\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"C:\\Users\\minqliu\\AppData\\Local\\Temp\\ipykernel_29864\\2602229280.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
						"  net_new.load_state_dict(torch.load('model.pth'))\n"
					]
				}
			],
			"source": [
				"# 81. 保存与加载模型\n",
				"torch.save(net_cls.state_dict(), 'model.pth')\n",
				"net_new = nn.Sequential(\n",
				"    nn.Linear(4,5),\n",
				"    nn.ReLU(),\n",
				"    nn.Linear(5,2)\n",
				")\n",
				"net_new.load_state_dict(torch.load('model.pth'))\n",
				"print(\"Loaded model.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b69629b6",
			"metadata": {},
			"source": [
				"## torch.nn.init"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1012,
			"id": "32cfb11b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[-0.2353,  0.2804, -0.0938,  0.1366,  0.1233,  0.2667, -0.3237, -0.2536,\n",
						"         -0.2945,  0.0401],\n",
						"        [-0.2769,  0.2773,  0.0810,  0.2419,  0.3719, -0.1447,  0.3678, -0.0145,\n",
						"         -0.2911, -0.3911]], grad_fn=<SliceBackward0>)\n"
					]
				}
			],
			"source": [
				"# 82. nn.init.xavier_uniform_, kaiming_uniform_\n",
				"import torch.nn.init as init\n",
				"\n",
				"my_layer = nn.Linear(10,20)\n",
				"init.xavier_uniform_(my_layer.weight)\n",
				"init.zeros_(my_layer.bias)\n",
				"print(my_layer.weight[:2])"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9e7dd294",
			"metadata": {},
			"source": [
				"## torch.utils.tensorboard"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1013,
			"id": "b9259694",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Written scalar to TB.\n"
					]
				}
			],
			"source": [
				"# 83. TensorBoard summary writer\n",
				"from torch.utils.tensorboard import SummaryWriter\n",
				"writer = SummaryWriter('runs/exp1')\n",
				"fake_scalar = 0.5\n",
				"writer.add_scalar(\"my_metric\", fake_scalar, 0)\n",
				"writer.close()\n",
				"print(\"Written scalar to TB.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d272e393",
			"metadata": {},
			"source": [
				"## more functional: F.log_softmax, F.nll_loss"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1014,
			"id": "0d53b7ba",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(2.6374)\n"
					]
				}
			],
			"source": [
				"# 84. F.log_softmax, F.nll_loss\n",
				"logits_ = torch.randn(3,5)\n",
				"log_prob = F.log_softmax(logits_, dim=1)\n",
				"target_cls = torch.tensor([2,1,4])\n",
				"nll = F.nll_loss(log_prob, target_cls)\n",
				"print(nll)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a4110405",
			"metadata": {},
			"source": [
				"## some Activation modules"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1015,
			"id": "09734a96",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0.2689, 0.5000, 0.7311]) tensor([-0.7616,  0.0000,  0.7616])\n"
					]
				}
			],
			"source": [
				"# 85. nn.Sigmoid, nn.Tanh\n",
				"sig_ = nn.Sigmoid()\n",
				"tnh_ = nn.Tanh()\n",
				"inp_act = torch.tensor([-1.0,0.0,1.0])\n",
				"print(sig_(inp_act), tnh_(inp_act))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "18273718",
			"metadata": {},
			"source": [
				"## WeightedLoss example"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1016,
			"id": "b60e68a3",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(1.1309)\n"
					]
				}
			],
			"source": [
				"# 86. CrossEntropyLoss with weight\n",
				"wt = torch.tensor([1.0,2.0])\n",
				"weighted_ce = nn.CrossEntropyLoss(weight=wt)\n",
				"logits_w = torch.randn(3,2)\n",
				"labels_w = torch.tensor([0,1,1])\n",
				"loss_w = weighted_ce(logits_w, labels_w)\n",
				"print(loss_w)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e6c848a9",
			"metadata": {},
			"source": [
				"## Non-differentiable ops"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1017,
			"id": "1acfc424",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1, 1, 0]) False\n"
					]
				}
			],
			"source": [
				"# 87. torch.argmax with no grad\n",
				"argmax_val = torch.argmax(logits_w, dim=1)\n",
				"print(argmax_val, argmax_val.requires_grad)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "555e44f7",
			"metadata": {},
			"source": [
				"## .grad_fn attribute"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1018,
			"id": "a713e34e",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<AddmmBackward0 object at 0x000001FD39BF5C30>\n"
					]
				}
			],
			"source": [
				"# 88. .grad_fn\n",
				"p_ = net_cls(torch.randn(1,4))\n",
				"print(p_.grad_fn)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "df5d85cc",
			"metadata": {},
			"source": [
				"## torch.autograd.grad"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1019,
			"id": "3b2bc460",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(tensor(12.),)\n"
					]
				}
			],
			"source": [
				"# 89. torch.autograd.grad\n",
				"x_ = torch.tensor(2.0, requires_grad=True)\n",
				"y_ = x_**3\n",
				"grad_val = torch.autograd.grad(y_, x_)\n",
				"print(grad_val)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a5674d0b",
			"metadata": {},
			"source": [
				"## hooking into modules"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1020,
			"id": "c2b77eff",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n"
					]
				}
			],
			"source": [
				"# 90. register_forward_hook\n",
				"def fwd_hook(m, inp, outp):\n",
				"    print(\"Forward hook triggered.\", m)\n",
				"\n",
				"net_cls[0].register_forward_hook(fwd_hook)\n",
				"_ = net_cls(torch.randn(1,4))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "647b5fc1",
			"metadata": {},
			"source": [
				"## Dtype conversions"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1021,
			"id": "0eca2c02",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.int32\n"
					]
				}
			],
			"source": [
				"# 91. .to(torch.float64), .to(torch.int)\n",
				"dt_ = x.to(torch.int)\n",
				"print(dt_.dtype)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e01b52f9",
			"metadata": {},
			"source": [
				"## Set random seed"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1022,
			"id": "6e0c9d28",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0.8823, 0.9150])\n"
					]
				}
			],
			"source": [
				"# 92. torch.manual_seed\n",
				"torch.manual_seed(42)\n",
				"print(torch.rand(2))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "66a4e674",
			"metadata": {},
			"source": [
				"## partial or full wrapping of python ops"
			]
		},
		{
			"cell_type": "markdown",
			"id": "8445884d",
			"metadata": {},
			"source": [
				"## tolist() or numpy() conversion"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1023,
			"id": "051904ab",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[1. 2. 3.] <class 'numpy.ndarray'>\n"
					]
				}
			],
			"source": [
				"# 93. x.numpy()  (requires x on CPU and not require_grad)\n",
				"cpu_x = x.cpu().detach()\n",
				"arr_np = cpu_x.numpy()\n",
				"print(arr_np, type(arr_np))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1024,
			"id": "1eba7efb",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[1.0, 2.0, 3.0]\n"
					]
				}
			],
			"source": [
				"# 94. .tolist()\n",
				"print(cpu_x.tolist())"
			]
		},
		{
			"cell_type": "markdown",
			"id": "525acb26",
			"metadata": {},
			"source": [
				"## advanced indexing"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1025,
			"id": "4f1d87fa",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([10, 30, 40])\n",
						"tensor([10, 30])\n"
					]
				}
			],
			"source": [
				"# 95. x[[0,2]] etc.\n",
				"arr_adv = torch.tensor([10,20,30,40])\n",
				"print(arr_adv[[0,2,3]])\n",
				"bool_mask = torch.tensor([True,False,True,False])\n",
				"print(arr_adv[bool_mask])"
			]
		},
		{
			"cell_type": "markdown",
			"id": "49c7a131",
			"metadata": {},
			"source": [
				"## advanced broadcasting"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1026,
			"id": "eb0d3fbc",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([3, 4])\n"
					]
				}
			],
			"source": [
				"# 96. broadcast shapes\n",
				"a_ = torch.randn(3,1)\n",
				"b_ = torch.randn(1,4)\n",
				"c_ = a_ + b_  # shape= (3,4)\n",
				"print(c_.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "ac071195",
			"metadata": {},
			"source": [
				"## in-place ops: add_, sub_, etc"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1027,
			"id": "24ce8f09",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([6., 7., 8.])\n"
					]
				}
			],
			"source": [
				"# 97. add_\n",
				"tmp_ = torch.tensor([1.0,2.0,3.0])\n",
				"tmp_.add_(5)\n",
				"print(tmp_)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "40e822b6",
			"metadata": {},
			"source": [
				"## accumulative grads"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d04c8352",
			"metadata": {},
			"source": [
				"## final 3 to complete 100"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1028,
			"id": "b80dec20",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(tensor([1, 2]), tensor([3, 4]), tensor([5, 6]))\n"
					]
				}
			],
			"source": [
				"# 98. torch.split\n",
				"split_val = torch.tensor([1,2,3,4,5,6])\n",
				"spl = torch.split(split_val, split_size_or_sections=2)\n",
				"print(spl)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1029,
			"id": "e8aa5838",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(tensor([1, 2]), tensor([3, 4]), tensor([5, 6]))\n"
					]
				}
			],
			"source": [
				"# 99. torch.chunk\n",
				"ch = torch.chunk(split_val, chunks=3)\n",
				"print(ch)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1030,
			"id": "42f86b8f",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"We've reached 100 examples.\n"
					]
				}
			],
			"source": [
				"# 100. pythonic: del x.grad\n",
				"w.grad = None  # or w.grad.zero_()\n",
				"print(\"We've reached 100 examples.\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1031,
			"id": "ec2aba75",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"True\n"
					]
				}
			],
			"source": [
				"# 101. torch.nn.Parameter\n",
				"param_var = nn.Parameter(torch.randn(3,3))\n",
				"print(param_var.requires_grad)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1032,
			"id": "646c1535",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"0.weight torch.Size([5, 4])\n",
						"0.bias torch.Size([5])\n",
						"2.weight torch.Size([2, 5])\n",
						"2.bias torch.Size([2])\n"
					]
				}
			],
			"source": [
				"# 102. model.parameters() vs model.named_parameters()\n",
				"for name, param in net_cls.named_parameters():\n",
				"    print(name, param.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1033,
			"id": "c48b1b2f",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Weights re-inited.\n"
					]
				}
			],
			"source": [
				"# 103. weight init example\n",
				"def init_weights(m):\n",
				"    if isinstance(m, nn.Linear):\n",
				"        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
				"        nn.init.constant_(m.bias, 0.0)\n",
				"\n",
				"net_cls.apply(init_weights)\n",
				"print(\"Weights re-inited.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6543f38d",
			"metadata": {},
			"source": [
				"## Another advanced: registering buffers"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1034,
			"id": "ee834cdf",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"MyModule()\n"
					]
				}
			],
			"source": [
				"# 104. register_buffer\n",
				"class MyModule(nn.Module):\n",
				"    def __init__(self):\n",
				"        super().__init__()\n",
				"        self.register_buffer('running_mean', torch.zeros(3))\n",
				"m_mod = MyModule()\n",
				"print(m_mod)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e9ef5249",
			"metadata": {},
			"source": [
				"## torch.distributions usage (not always in top usage, but let's do 1-2 examples)."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1035,
			"id": "56e62214",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([ 0.5568, -0.8123,  1.1964,  0.8613, -1.3682]) tensor([-1.0739, -1.2489, -1.6346, -1.2899, -1.8549])\n"
					]
				}
			],
			"source": [
				"# 105. distributions: Normal\n",
				"from torch.distributions import Normal\n",
				"dist_ = Normal(loc=0.0, scale=1.0)\n",
				"samples_ = dist_.sample((5,))\n",
				"print(samples_, dist_.log_prob(samples_))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5ec9a216",
			"metadata": {},
			"source": [
				"## torch.einsum"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1036,
			"id": "253586e5",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 4])\n"
					]
				}
			],
			"source": [
				"# 106. torch.einsum\n",
				"a_ = torch.randn(2,3)\n",
				"b_ = torch.randn(3,4)\n",
				"res_ein = torch.einsum('ij,jk->ik', a_, b_)\n",
				"print(res_ein.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "707dbddf",
			"metadata": {},
			"source": [
				"## HPC advanced: pinned memory not in top usage.\n",
				"## We'll skip."
			]
		},
		{
			"cell_type": "markdown",
			"id": "c47ba99f",
			"metadata": {},
			"source": [
				"## torch.nn.utils.clip_grad_norm_"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1037,
			"id": "a8cf8c79",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"clip_grad_norm_ done.\n"
					]
				}
			],
			"source": [
				"# 107. clip_grad_norm_\n",
				"net_temp = nn.Linear(4,3)\n",
				"opt_temp = optim.SGD(net_temp.parameters(), lr=0.01)\n",
				"dummy_input = torch.randn(1,4)\n",
				"dummy_target = torch.tensor([1])\n",
				"criterion_ce = nn.CrossEntropyLoss()\n",
				"\n",
				"opt_temp.zero_grad()\n",
				"out_temp = net_temp(dummy_input)\n",
				"loss_temp = criterion_ce(out_temp, dummy_target)\n",
				"loss_temp.backward()\n",
				"torch.nn.utils.clip_grad_norm_(net_temp.parameters(), max_norm=2.0)\n",
				"opt_temp.step()\n",
				"print(\"clip_grad_norm_ done.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "ddfa91f4",
			"metadata": {},
			"source": [
				"## torch.nn.utils.rnn.pack_padded_sequence, pad_packed_sequence"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1038,
			"id": "132875b5",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"PackedSequence(data=tensor([1, 4, 2, 5, 3]), batch_sizes=tensor([2, 2, 1]), sorted_indices=tensor([0, 1]), unsorted_indices=tensor([0, 1]))\n"
					]
				}
			],
			"source": [
				"# 108. pack_padded_sequence example\n",
				"from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
				"seqs = [torch.tensor([1,2,3]), torch.tensor([4,5])]  # different length\n",
				"lengths = [3,2]\n",
				"padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True)\n",
				"packed = pack_padded_sequence(padded, lengths=lengths, batch_first=True, enforce_sorted=False)\n",
				"print(packed)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f8b82961",
			"metadata": {},
			"source": [
				"## set_requires_grad"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1039,
			"id": "a83c0be9",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"True\n"
					]
				}
			],
			"source": [
				"# 109. x.requires_grad_(True)\n",
				"no_grad_t = torch.randn(3)\n",
				"no_grad_t.requires_grad_(True)\n",
				"print(no_grad_t.requires_grad)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "124eeb4c",
			"metadata": {},
			"source": [
				"## backward with gradient arg"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1040,
			"id": "363e89c8",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([4., 6.])\n"
					]
				}
			],
			"source": [
				"# 110. y.backward(gradient=some_tensor)\n",
				"x_2 = torch.tensor([2.0,3.0], requires_grad=True)\n",
				"y_2 = x_2 * x_2\n",
				"grad_arg = torch.tensor([1.0, 1.0])\n",
				"y_2.backward(gradient=grad_arg)\n",
				"print(x_2.grad)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "de32eef4",
			"metadata": {},
			"source": [
				"## advanced spool"
			]
		},
		{
			"cell_type": "markdown",
			"id": "906f04bc",
			"metadata": {},
			"source": [
				"## leftover"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1041,
			"id": "12b297a1",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 6, 32, 32])\n"
					]
				}
			],
			"source": [
				"# 111. functional conv2d\n",
				"img_t = torch.randn(1,3,32,32)\n",
				"weight_c = torch.randn(6,3,3,3)\n",
				"bias_c = torch.randn(6)\n",
				"out_fn = F.conv2d(img_t, weight_c, bias_c, stride=1, padding=1)\n",
				"print(out_fn.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1042,
			"id": "ab9da79d",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 3])\n"
					]
				}
			],
			"source": [
				"# 112. functional linear\n",
				"in_lin = torch.randn(2,5)\n",
				"weight_lin = torch.randn(3,5)\n",
				"bias_lin = torch.randn(3)\n",
				"out_linfn = F.linear(in_lin, weight_lin, bias_lin)\n",
				"print(out_linfn.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "0bf584a1",
			"metadata": {},
			"source": [
				"## reduce ops: product, cumsum, cumprod"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1043,
			"id": "8b5f4c64",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(24)\n",
						"tensor([ 1,  3,  6, 10])\n",
						"tensor([ 1,  2,  6, 24])\n"
					]
				}
			],
			"source": [
				"# 113. torch.prod, torch.cumsum, torch.cumprod\n",
				"vals_c = torch.tensor([1,2,3,4])\n",
				"print(torch.prod(vals_c))\n",
				"print(torch.cumsum(vals_c, dim=0))\n",
				"print(torch.cumprod(vals_c, dim=0))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "aff33430",
			"metadata": {},
			"source": [
				"## bitwise ops: torch.bitwise_and, bitwise_or"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1044,
			"id": "fc37f233",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1, 1, 4])\n",
						"tensor([1, 3, 5])\n"
					]
				}
			],
			"source": [
				"# 114. bitwise ops\n",
				"a_b = torch.tensor([1,3,5])\n",
				"b_b = torch.tensor([1,1,4])\n",
				"print(torch.bitwise_and(a_b, b_b))\n",
				"print(torch.bitwise_or(a_b, b_b))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "1a3d6979",
			"metadata": {},
			"source": [
				"## RNG states: get_rng_state, set_rng_state"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1045,
			"id": "8d89e4d2",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([5056])\n"
					]
				}
			],
			"source": [
				"# 115. torch.get_rng_state\n",
				"rng_st = torch.get_rng_state()\n",
				"print(rng_st.shape)\n",
				"# we can set back: torch.set_rng_state(rng_st)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "0f09fe68",
			"metadata": {},
			"source": [
				"## custom autograd function"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1046,
			"id": "2f4b2194",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(6.)\n"
					]
				}
			],
			"source": [
				"# 116. custom autograd\n",
				"class MySquareFunc(torch.autograd.Function):\n",
				"    @staticmethod\n",
				"    def forward(ctx, x):\n",
				"        ctx.save_for_backward(x)\n",
				"        return x*x\n",
				"    @staticmethod\n",
				"    def backward(ctx, grad_output):\n",
				"        (x,) = ctx.saved_tensors\n",
				"        grad_input = 2*x*grad_output\n",
				"        return grad_input\n",
				"\n",
				"inp_sq = torch.tensor(3.0, requires_grad=True)\n",
				"out_sq = MySquareFunc.apply(inp_sq)\n",
				"out_sq.backward()\n",
				"print(inp_sq.grad)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "67b947ac",
			"metadata": {},
			"source": [
				"## DataParallel (if multiple GPUs) - skip if not available"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a10ad169",
			"metadata": {},
			"source": [
				"## advanced losses"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1047,
			"id": "eb536f17",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(0.0200)\n"
					]
				}
			],
			"source": [
				"# 117. nn.SmoothL1Loss\n",
				"sl1 = nn.SmoothL1Loss()\n",
				"pred_sl1 = torch.tensor([0.8, 1.2])\n",
				"tgt_sl1 = torch.tensor([1.0,1.0])\n",
				"loss_s1 = sl1(pred_sl1, tgt_sl1)\n",
				"print(loss_s1)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1048,
			"id": "1745d24f",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(0.2000)\n"
					]
				}
			],
			"source": [
				"# 118. nn.L1Loss\n",
				"l1_ = nn.L1Loss()\n",
				"loss_l1val = l1_(pred_sl1, tgt_sl1)\n",
				"print(loss_l1val)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c55bf8b0",
			"metadata": {},
			"source": [
				"## advanced init"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1049,
			"id": "d9fbcc57",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[ 0.1635,  0.8652,  0.4507,  0.1471],\n",
						"        [ 0.9385,  0.0117, -0.3295, -0.1021],\n",
						"        [ 0.2459, -0.4008,  0.8010, -0.3705],\n",
						"        [ 0.1787, -0.3012,  0.2160,  0.9114]])\n"
					]
				}
			],
			"source": [
				"# 119. orthogonal_\n",
				"w_orth = torch.empty(4,4)\n",
				"nn.init.orthogonal_(w_orth)\n",
				"print(w_orth)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "0cadb175",
			"metadata": {},
			"source": [
				"## freq usage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1050,
			"id": "b2a80261",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0.4140, 0.7394, 0.3248])\n"
					]
				}
			],
			"source": [
				"# 120. nn.CosineSimilarity\n",
				"cosim = nn.CosineSimilarity(dim=1)\n",
				"v1 = torch.randn(3,4)\n",
				"v2 = torch.randn(3,4)\n",
				"cs_out = cosim(v1,v2)\n",
				"print(cs_out)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "694f2487",
			"metadata": {},
			"source": [
				"## gradient accum snippet"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1051,
			"id": "2e77484c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"accum done.\n"
					]
				}
			],
			"source": [
				"# 121. typical accumulate grad\n",
				"for i, (bx,by) in enumerate(loader):\n",
				"    optim_sgd.zero_grad()\n",
				"    preds_ = net_cls(bx)\n",
				"    loss_val = criterion(preds_, by)\n",
				"    loss_val.backward()\n",
				"    optim_sgd.step()\n",
				"print(\"accum done.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9cba92c0",
			"metadata": {},
			"source": [
				"## no usage"
			]
		},
		{
			"cell_type": "markdown",
			"id": "56a4b02f",
			"metadata": {},
			"source": [
				"## advanced RNN usage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1052,
			"id": "07c27d13",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 4, 6]) torch.Size([1, 2, 6])\n"
					]
				}
			],
			"source": [
				"# 122. nn.RNN\n",
				"rnn_ = nn.RNN(input_size=5, hidden_size=6, batch_first=True)\n",
				"seq_ = torch.randn(2,4,5)\n",
				"out_rn, h_rn = rnn_(seq_)\n",
				"print(out_rn.shape, h_rn.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6bf559b2",
			"metadata": {},
			"source": [
				"## conv1d example"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1053,
			"id": "54441795",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 4, 8])\n"
					]
				}
			],
			"source": [
				"# 123. nn.Conv1d\n",
				"conv1 = nn.Conv1d(in_channels=2, out_channels=4, kernel_size=3)\n",
				"in_1d = torch.randn(2,2,10)  # batch=2, channels=2, length=10\n",
				"out_1d = conv1(in_1d)\n",
				"print(out_1d.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f9076c3f",
			"metadata": {},
			"source": [
				"## convTranspose2d"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1054,
			"id": "6ece8caf",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 2, 17, 17])\n"
					]
				}
			],
			"source": [
				"# 124. nn.ConvTranspose2d\n",
				"deconv = nn.ConvTranspose2d(4,2, kernel_size=3, stride=2)\n",
				"in_de = torch.randn(1,4,8,8)\n",
				"out_de = deconv(in_de)\n",
				"print(out_de.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "8ec94fd3",
			"metadata": {},
			"source": [
				"## upsample"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1055,
			"id": "12c359fe",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 3, 32, 32])\n"
					]
				}
			],
			"source": [
				"# 125. nn.Upsample\n",
				"up_ = nn.Upsample(scale_factor=2, mode='nearest')\n",
				"img_sm = torch.randn(1,3,16,16)\n",
				"img_big = up_(img_sm)\n",
				"print(img_big.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9136e69b",
			"metadata": {},
			"source": [
				"## flatten vs view"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1056,
			"id": "f5f4c065",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 10])\n"
					]
				}
			],
			"source": [
				"# 126. nn.Flatten in sequential\n",
				"flat_seq = nn.Sequential(\n",
				"    nn.Conv2d(3,6,3),\n",
				"    nn.ReLU(),\n",
				"    nn.Flatten(),\n",
				"    nn.Linear(6*30*30,10)\n",
				")\n",
				"img_2 = torch.randn(2,3,32,32)\n",
				"o_ = flat_seq(img_2)\n",
				"print(o_.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "45909371",
			"metadata": {},
			"source": [
				"## handle dimension carefully"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1057,
			"id": "37d7ce5a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"0.weight torch.Size([6, 3, 3, 3])\n",
						"0.bias torch.Size([6])\n",
						"3.weight torch.Size([10, 5400])\n",
						"3.bias torch.Size([10])\n"
					]
				}
			],
			"source": [
				"# 127. keep track or parameter usage\n",
				"for name, param in flat_seq.named_parameters():\n",
				"    print(name, param.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "7d85c675",
			"metadata": {},
			"source": [
				"## marginrankingloss"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1058,
			"id": "5f726a5a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(0.7500)\n"
					]
				}
			],
			"source": [
				"# 128. nn.MarginRankingLoss\n",
				"mrl = nn.MarginRankingLoss(margin=1.0)\n",
				"x1_ = torch.tensor([0.8,1.0])\n",
				"x2_ = torch.tensor([0.5,1.2])\n",
				"y_sign = torch.tensor([1, -1])\n",
				"loss_mr = mrl(x1_, x2_, y_sign)\n",
				"print(loss_mr)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "65f46657",
			"metadata": {},
			"source": [
				"## label_smoothing"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1059,
			"id": "d1d7745a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(2.0009)\n"
					]
				}
			],
			"source": [
				"# 129. CrossEntropyLoss with label_smoothing\n",
				"ls_ce = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
				"logits_ls = torch.randn(3,5)\n",
				"target_ls = torch.tensor([1,0,4])\n",
				"loss_ls = ls_ce(logits_ls, target_ls)\n",
				"print(loss_ls)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "423b2668",
			"metadata": {},
			"source": [
				"## multihead attention"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1060,
			"id": "57a09ab4",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 5, 8]) torch.Size([2, 5, 5])\n"
					]
				}
			],
			"source": [
				"# 130. nn.MultiheadAttention\n",
				"mha = nn.MultiheadAttention(embed_dim=8, num_heads=2, batch_first=True)\n",
				"q_ = torch.randn(2,5,8)\n",
				"k_ = torch.randn(2,5,8)\n",
				"v_ = torch.randn(2,5,8)\n",
				"attn_output, attn_weights = mha(q_, k_, v_)\n",
				"print(attn_output.shape, attn_weights.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5e669ec1",
			"metadata": {},
			"source": [
				"## transformer"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1061,
			"id": "4e4d68fc",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([6, 2, 8])\n"
					]
				}
			],
			"source": [
				"# 131. nn.Transformer\n",
				"transformer = nn.Transformer(d_model=8, nhead=2, num_encoder_layers=2, num_decoder_layers=2)\n",
				"src = torch.randn(5,2,8)\n",
				"tgt = torch.randn(6,2,8)\n",
				"out_trans = transformer(src, tgt)\n",
				"print(out_trans.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "81224dcb",
			"metadata": {},
			"source": [
				"## param groups in optimizer"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1062,
			"id": "7d6c5cd5",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"SGD (\n",
						"Parameter Group 0\n",
						"    dampening: 0\n",
						"    differentiable: False\n",
						"    foreach: None\n",
						"    fused: None\n",
						"    lr: 0.01\n",
						"    maximize: False\n",
						"    momentum: 0\n",
						"    nesterov: False\n",
						"    weight_decay: 0\n",
						"\n",
						"Parameter Group 1\n",
						"    dampening: 0\n",
						"    differentiable: False\n",
						"    foreach: None\n",
						"    fused: None\n",
						"    lr: 0.001\n",
						"    maximize: False\n",
						"    momentum: 0\n",
						"    nesterov: False\n",
						"    weight_decay: 0\n",
						")\n"
					]
				}
			],
			"source": [
				"# 132. param groups\n",
				"layer1 = nn.Linear(4,4)\n",
				"layer2 = nn.Linear(4,2)\n",
				"opt_gr = optim.SGD([\n",
				"    {'params': layer1.parameters(), 'lr': 0.01},\n",
				"    {'params': layer2.parameters(), 'lr': 0.001}\n",
				"], lr=0.1)  # global lr=0.1 ignored?\n",
				"print(opt_gr)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "52dae323",
			"metadata": {},
			"source": [
				"## cyclical lr"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1063,
			"id": "e1e4b40b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"0 0.002800000000000002\n",
						"1 0.0046\n",
						"2 0.006400000000000001\n"
					]
				}
			],
			"source": [
				"# 133. CyclicLR\n",
				"cyc_opt = optim.SGD(net_cls.parameters(), lr=0.01)\n",
				"scheduler_cyc = optim.lr_scheduler.CyclicLR(cyc_opt, base_lr=0.001, max_lr=0.01, step_size_up=5)\n",
				"for i in range(3):\n",
				"    cyc_opt.step()\n",
				"    scheduler_cyc.step()\n",
				"    print(i, cyc_opt.param_groups[0]['lr'])"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b5d197e4",
			"metadata": {},
			"source": [
				"## early stopping is user-defined"
			]
		},
		{
			"cell_type": "markdown",
			"id": "06e61a8c",
			"metadata": {},
			"source": [
				"## weight decay in optimizer"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1064,
			"id": "084243da",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Adam (\n",
						"Parameter Group 0\n",
						"    amsgrad: False\n",
						"    betas: (0.9, 0.999)\n",
						"    capturable: False\n",
						"    differentiable: False\n",
						"    eps: 1e-08\n",
						"    foreach: None\n",
						"    fused: None\n",
						"    lr: 0.001\n",
						"    maximize: False\n",
						"    weight_decay: 1e-05\n",
						")\n"
					]
				}
			],
			"source": [
				"# 134. weight_decay param\n",
				"opt_wd = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
				"print(opt_wd)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "21cdf674",
			"metadata": {},
			"source": [
				"## micro-libraries: torchtext, torchvision, etc."
			]
		},
		{
			"cell_type": "markdown",
			"id": "49bc1b18",
			"metadata": {},
			"source": [
				"## final expansions: let's keep going"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1065,
			"id": "537b0df2",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Switched modes.\n"
					]
				}
			],
			"source": [
				"# 135. Example: .eval() and .train()\n",
				"net_cls.train()\n",
				"net_cls.eval()\n",
				"print(\"Switched modes.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6e6d1677",
			"metadata": {},
			"source": [
				"## example: gradient accum skip."
			]
		},
		{
			"cell_type": "markdown",
			"id": "6813b54b",
			"metadata": {},
			"source": [
				"## half precision: .half()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1066,
			"id": "021bab42",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"torch.float16\n"
					]
				}
			],
			"source": [
				"# 136. half precision\n",
				"hp = net_cls.half()\n",
				"inp_fp16 = torch.randn(2,4).half()\n",
				"out_fp16 = hp(inp_fp16)\n",
				"print(out_fp16.dtype)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "ce6baf88",
			"metadata": {},
			"source": [
				"## model to eval, no grad"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1067,
			"id": "9a368430",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"eval done.\n"
					]
				}
			],
			"source": [
				"# 137. typical eval usage\n",
				"hp.eval()\n",
				"with torch.no_grad():\n",
				"    res_e = hp(inp_fp16)\n",
				"print(\"eval done.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d07bf4ea",
			"metadata": {},
			"source": [
				"## zeroing partial usage"
			]
		},
		{
			"cell_type": "markdown",
			"id": "cc2928f7",
			"metadata": {},
			"source": [
				"## transformation snippet"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b08c456f",
			"metadata": {},
			"source": [
				"## let us do .nonzero()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1068,
			"id": "1f622e50",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(tensor([1, 3]),)\n"
					]
				}
			],
			"source": [
				"# 138. .nonzero\n",
				"aa_ = torch.tensor([0,1,0,3,0])\n",
				"nz = aa_.nonzero(as_tuple=True)\n",
				"print(nz)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "77c009d6",
			"metadata": {},
			"source": [
				"## gather advanced"
			]
		},
		{
			"cell_type": "markdown",
			"id": "27ab340e",
			"metadata": {},
			"source": [
				"## we do 62 more"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1069,
			"id": "df48b786",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[0.6003, 0.1695],\n",
						"        [1.2402, 1.0446],\n",
						"        [1.8576, 0.0402]]) tensor([[3, 1],\n",
						"        [3, 2],\n",
						"        [2, 1]])\n"
					]
				}
			],
			"source": [
				"# 139. advanced example using gather for topk\n",
				"values_, indices_ = torch.topk(logits_, 2, dim=1)\n",
				"print(values_, indices_)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d9ca5850",
			"metadata": {},
			"source": [
				"## autograd grad mode"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1070,
			"id": "94949c87",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"temp done.\n"
					]
				}
			],
			"source": [
				"# 140. torch.set_grad_enabled\n",
				"torch.set_grad_enabled(False)\n",
				"tmp_no_grad = net_cls(torch.randn(2,4).half())\n",
				"torch.set_grad_enabled(True)\n",
				"print(\"temp done.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f916773d",
			"metadata": {},
			"source": [
				"## advanced indexing 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1071,
			"id": "c143c999",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[ 0, 10,  0,  0],\n",
						"        [ 0,  0,  0, 20]])\n"
					]
				}
			],
			"source": [
				"# 141. scatter\n",
				"z_sc = torch.zeros(2,4, dtype=torch.int64)\n",
				"idx_sc = torch.tensor([[1],[3]], dtype=torch.int64)\n",
				"src_sc = torch.tensor([10,20], dtype=torch.int64)\n",
				"z_sc.scatter_(dim=1, index=idx_sc, src=src_sc.unsqueeze(1))\n",
				"print(z_sc)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "2fcdd6ac",
			"metadata": {},
			"source": [
				"## complex usage skip"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1072,
			"id": "d4d54a76",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1.+2.j, 3.+4.j])\n"
					]
				}
			],
			"source": [
				"# 142. example: complex\n",
				"cplx = torch.tensor([1+2j, 3+4j], dtype=torch.cfloat)\n",
				"print(cplx)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "ccd2ee68",
			"metadata": {},
			"source": [
				"## spectral ops (torch.fft) if new version"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1073,
			"id": "979a7e6b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-2.8946+0.3844j, -0.4065-0.3411j,  1.6987-0.4720j,  1.6165+0.7065j])\n"
					]
				}
			],
			"source": [
				"# 143. torch.fft.fft\n",
				"try:\n",
				"    import torch.fft\n",
				"    sig_fft = torch.fft.fft(torch.randn(4, dtype=torch.cfloat))\n",
				"    print(sig_fft)\n",
				"except ImportError:\n",
				"    print(\"torch.fft not available.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d262b125",
			"metadata": {},
			"source": [
				"## random sampler"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1074,
			"id": "92292b88",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[33, 49, 73, 64, 10]\n"
					]
				}
			],
			"source": [
				"# 144. RandomSampler\n",
				"from torch.utils.data import RandomSampler\n",
				"sampler = RandomSampler(ds)\n",
				"print(list(sampler)[:5])"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e5b2399b",
			"metadata": {},
			"source": [
				"## WeightedRandomSampler"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1075,
			"id": "0af4009c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[3, 38, 80, 41, 97, 31, 83, 31, 75, 58]\n"
					]
				}
			],
			"source": [
				"# 145. WeightedRandomSampler\n",
				"from torch.utils.data import WeightedRandomSampler\n",
				"sample_weights = [1]*len(ds)\n",
				"wrs = WeightedRandomSampler(sample_weights, num_samples=10, replacement=True)\n",
				"sampled_indices = list(wrs)\n",
				"print(sampled_indices)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "bf18e6f9",
			"metadata": {},
			"source": [
				"## Weighted sampling in loader"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1076,
			"id": "6da7cefc",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([4, 4]) tensor([1, 0, 1, 1])\n"
					]
				}
			],
			"source": [
				"# 146. DataLoader with WeightedRandomSampler\n",
				"loader_w = DataLoader(ds, batch_size=4, sampler=wrs)\n",
				"for bx,by in loader_w:\n",
				"    print(bx.shape, by)\n",
				"    break"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b624a46f",
			"metadata": {},
			"source": [
				"## SubsetRandomSampler"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1077,
			"id": "5cb56da8",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[-1.2472, -0.1509, -1.4873, -1.0110],\n",
						"        [ 0.2983,  0.7805,  0.9919, -0.3711]]) tensor([0, 1])\n"
					]
				}
			],
			"source": [
				"# 147. SubsetRandomSampler\n",
				"from torch.utils.data import SubsetRandomSampler\n",
				"indices_srs = [0,2,4,6]\n",
				"srs = SubsetRandomSampler(indices_srs)\n",
				"loader_srs = DataLoader(ds, batch_size=2, sampler=srs)\n",
				"for bx,by in loader_srs:\n",
				"    print(bx, by)\n",
				"    break"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b4bc8ad1",
			"metadata": {},
			"source": [
				"## tri-level logs"
			]
		},
		{
			"cell_type": "markdown",
			"id": "ec473831",
			"metadata": {},
			"source": [
				"## autograd anom detect"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1078,
			"id": "a4967e55",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"anomaly detection.\n"
					]
				}
			],
			"source": [
				"# 148. torch.autograd.set_detect_anomaly(True)\n",
				"with torch.autograd.set_detect_anomaly(True):\n",
				"    x_ano = torch.tensor([2.0], requires_grad=True)\n",
				"    y_ano = x_ano**3\n",
				"    y_ano.backward()\n",
				"print(\"anomaly detection.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "bd2b7b67",
			"metadata": {},
			"source": [
				"## pinned memory usage: skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5802a3e1",
			"metadata": {},
			"source": [
				"## advanced BFS or topological skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "3b79a5eb",
			"metadata": {},
			"source": [
				"## 2 more advanced aggregator"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c274658c",
			"metadata": {},
			"source": [
				"## final 50 examples or so, let's accelerate"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1079,
			"id": "a1c8e506",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 129, 63, 2])\n"
					]
				}
			],
			"source": [
				"# 149. torch.stft / torch.istft (some versions)\n",
				"wav = torch.randn(1,4000)\n",
				"stft_v = torch.stft(wav, n_fft=256, return_complex=False)\n",
				"print(stft_v.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "893edbec",
			"metadata": {},
			"source": [
				"## pad ops: F.pad"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1080,
			"id": "81d36efb",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 3, 14, 12])\n"
					]
				}
			],
			"source": [
				"# 150. F.pad\n",
				"padded_2d = F.pad(torch.randn(1,3,10,10), pad=(1,1,2,2))\n",
				"print(padded_2d.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "4c2b0c78",
			"metadata": {},
			"source": [
				"## grouping param usage"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a496bae2",
			"metadata": {},
			"source": [
				"## partial coverage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1081,
			"id": "cf229adc",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 3, 8, 8])\n"
					]
				}
			],
			"source": [
				"# 151. torch.nn.ReflectionPad2d\n",
				"rpad2d = nn.ReflectionPad2d(2)\n",
				"inp_pad = torch.randn(1,3,4,4)\n",
				"out_pad = rpad2d(inp_pad)\n",
				"print(out_pad.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "4b8bf016",
			"metadata": {},
			"source": [
				"## advanced RNN utilities: nn.utils.rnn"
			]
		},
		{
			"cell_type": "markdown",
			"id": "cfdfa46f",
			"metadata": {},
			"source": [
				"## let's do ctc loss"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1082,
			"id": "c5ff9a2d",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(3.9878)\n"
					]
				}
			],
			"source": [
				"# 152. nn.CTCLoss\n",
				"ctc = nn.CTCLoss()\n",
				"log_probs = torch.randn(50,2,20).log_softmax(2).detach()\n",
				"targets = torch.randint(1,20,(2,30), dtype=torch.long)\n",
				"input_lengths = torch.full(size=(2,), fill_value=50, dtype=torch.long)\n",
				"target_lengths = torch.full(size=(2,), fill_value=30, dtype=torch.long)\n",
				"loss_ctc = ctc(log_probs, targets, input_lengths, target_lengths)\n",
				"print(loss_ctc)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9942012f",
			"metadata": {},
			"source": [
				"## matrix factorization example: torch.linalg"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1083,
			"id": "f506d061",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.return_types.linalg_svd(\n",
						"U=tensor([[-0.7071, -0.7071],\n",
						"        [-0.7071,  0.7071]]),\n",
						"S=tensor([3.0000, 1.0000]),\n",
						"Vh=tensor([[-0.7071, -0.7071],\n",
						"        [-0.7071,  0.7071]]))\n"
					]
				}
			],
			"source": [
				"# 153. torch.linalg.svd\n",
				"import torch.linalg as lalg\n",
				"svd_out = lalg.svd(mat2x2)\n",
				"print(svd_out)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "be74a812",
			"metadata": {},
			"source": [
				"## advanced partial usage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1084,
			"id": "a49f4a53",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 1]) torch.Size([2, 4])\n"
					]
				}
			],
			"source": [
				"# 154. torch.nn.utils.weight_norm\n",
				"wn_model = nn.Linear(4,2)\n",
				"wn_model = nn.utils.weight_norm(wn_model)\n",
				"print(wn_model.weight_g.shape, wn_model.weight_v.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "52848b8d",
			"metadata": {},
			"source": [
				"## torch.nn.parallel.DistributedDataParallel skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "957428da",
			"metadata": {},
			"source": [
				"## advanced quantization skip"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1085,
			"id": "c98c85ce",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 6, 4, 4])\n"
					]
				}
			],
			"source": [
				"# 155. Functional groupnorm\n",
				"gn_out = F.group_norm(torch.randn(2,6,4,4), num_groups=3)\n",
				"print(gn_out.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "cf28a41b",
			"metadata": {},
			"source": [
				"## advanced metrics skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a39755dd",
			"metadata": {},
			"source": [
				"## torch.cuda.empty_cache"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1086,
			"id": "2ed4e96a",
			"metadata": {},
			"outputs": [],
			"source": [
				"# 156. torch.cuda.empty_cache\n",
				"if torch.cuda.is_available():\n",
				"    torch.cuda.empty_cache()\n",
				"    print(\"Cache emptied.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "77d1a8d4",
			"metadata": {},
			"source": [
				"## layer hooks backward"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1087,
			"id": "9f257e92",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"backward hook set.\n"
					]
				}
			],
			"source": [
				"# 157. register_backward_hook is deprecated in latest PyTorch, use register_full_backward_hook\n",
				"def bw_hook(m, gin, gout):\n",
				"    print(\"Backward hook.\")\n",
				"\n",
				"if hasattr(net_cls[0], 'register_full_backward_hook'):\n",
				"    net_cls[0].register_full_backward_hook(bw_hook)\n",
				"else:\n",
				"    pass\n",
				"print(\"backward hook set.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "135eb32a",
			"metadata": {},
			"source": [
				"## jit script/tracing"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1088,
			"id": "5b6b11d5",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Forward hook triggered."
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						" Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Sequential(\n",
						"  original_name=Sequential\n",
						"  (0): Linear(original_name=Linear)\n",
						"  (1): ReLU(original_name=ReLU)\n",
						"  (2): Linear(original_name=Linear)\n",
						")\n"
					]
				}
			],
			"source": [
				"# 158. torch.jit.trace\n",
				"# Remove backward hooks before tracing\n",
				"for module in net_cls.modules():\n",
				"\tif hasattr(module, '_backward_hooks'):\n",
				"\t\tmodule._backward_hooks.clear()\n",
				"\n",
				"# Convert input tensor to half precision\n",
				"input_tensor = torch.randn(1, 4).half()\n",
				"\n",
				"traced_model = torch.jit.trace(net_cls, input_tensor)\n",
				"print(traced_model)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1089,
			"id": "165ea080",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"RecursiveScriptModule(\n",
						"  original_name=Sequential\n",
						"  (0): RecursiveScriptModule(original_name=Linear)\n",
						"  (1): RecursiveScriptModule(original_name=ReLU)\n",
						"  (2): RecursiveScriptModule(original_name=Linear)\n",
						")\n"
					]
				}
			],
			"source": [
				"# 159. torch.jit.save/torch.jit.load\n",
				"traced_model.save('traced_model.pt')\n",
				"loaded_tr = torch.jit.load('traced_model.pt')\n",
				"print(loaded_tr)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5b0a654a",
			"metadata": {},
			"source": [
				"## memory usage check: torch.cuda.memory_allocated"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1090,
			"id": "bfd8ed88",
			"metadata": {},
			"outputs": [],
			"source": [
				"# 160. memory_allocated\n",
				"if torch.cuda.is_available():\n",
				"    mem_used = torch.cuda.memory_allocated()\n",
				"    print(\"Mem used=\", mem_used)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "57890728",
			"metadata": {},
			"source": [
				"## philanthropic leftover"
			]
		},
		{
			"cell_type": "markdown",
			"id": "8159625f",
			"metadata": {},
			"source": [
				"## torch.nn.utils.prune"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1091,
			"id": "cb124f37",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[-0.0041,  0.0340,  0.0062, -0.0000],\n",
						"        [-0.0162, -0.0147, -0.0000, -0.0183],\n",
						"        [ 0.0362,  0.0032,  0.0073,  0.0035],\n",
						"        [-0.0237,  0.0277, -0.0000,  0.0000],\n",
						"        [-0.0000,  0.0108,  0.0000,  0.0113]], dtype=torch.float16,\n",
						"       grad_fn=<MulBackward0>)\n"
					]
				}
			],
			"source": [
				"# 161. prune example\n",
				"import torch.nn.utils.prune as prune\n",
				"\n",
				"prune.random_unstructured(net_cls[0], name='weight', amount=0.3)\n",
				"print(net_cls[0].weight)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9b7b7ce4",
			"metadata": {},
			"source": [
				"## example: partial Tensors"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6594bfef",
			"metadata": {},
			"source": [
				"## advanced scatter reduce"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1092,
			"id": "44e9d570",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[2., 0., 0., 0.],\n",
						"        [0., 3., 0., 0.]])\n"
					]
				}
			],
			"source": [
				"# 162. scatter add\n",
				"temp_sc = torch.zeros(2,4)\n",
				"idx_sa = torch.tensor([[0],[1]])\n",
				"src_sa = torch.tensor([[2.0],[3.0]])\n",
				"temp_sc.scatter_add_(dim=1, index=idx_sa, src=src_sa)\n",
				"print(temp_sc)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c7db986b",
			"metadata": {},
			"source": [
				"## advanced destructive ops"
			]
		},
		{
			"cell_type": "markdown",
			"id": "8194a9fb",
			"metadata": {},
			"source": [
				"## let's do 38 more"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1093,
			"id": "ee660077",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([4, 5])\n"
					]
				}
			],
			"source": [
				"# 163. torch.cdist\n",
				"a_cdist = torch.randn(4,3)\n",
				"b_cdist = torch.randn(5,3)\n",
				"dist_c = torch.cdist(a_cdist, b_cdist)\n",
				"print(dist_c.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "3e2cfdc3",
			"metadata": {},
			"source": [
				"## dtype is"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1094,
			"id": "48a9271b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.bool torch.int8 torch.float64\n"
					]
				}
			],
			"source": [
				"# 164. Checking dtypes\n",
				"print(torch.bool, torch.int8, torch.float64)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "10cb4bdc",
			"metadata": {},
			"source": [
				"## functional margin losses"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1095,
			"id": "82d2ff1f",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(0.2500)\n"
					]
				}
			],
			"source": [
				"# 165. F.margin_ranking_loss\n",
				"ma_loss = F.margin_ranking_loss(x1_, x2_, y_sign, margin=0.5)\n",
				"print(ma_loss)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "2dabc9cb",
			"metadata": {},
			"source": [
				"## advanced: pad sequence"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1096,
			"id": "e3ec6859",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[1, 2, 3],\n",
						"        [4, 5, 0]])\n"
					]
				}
			],
			"source": [
				"# 166. pad_sequence\n",
				"seq1 = torch.tensor([1,2,3])\n",
				"seq2 = torch.tensor([4,5])\n",
				"padded_seq = nn.utils.rnn.pad_sequence([seq1,seq2], batch_first=True)\n",
				"print(padded_seq)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f3ef16e8",
			"metadata": {},
			"source": [
				"## replicate for DP usage skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "45c86d2a",
			"metadata": {},
			"source": [
				"## advanced BFS skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "45c4577f",
			"metadata": {},
			"source": [
				"## .copy_ operation"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1097,
			"id": "671f9020",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([5., 6., 7.])\n"
					]
				}
			],
			"source": [
				"# 167. .copy_\n",
				"src_cpy = torch.tensor([5,6,7])\n",
				"dst_cpy = torch.zeros(3)\n",
				"dst_cpy.copy_(src_cpy)\n",
				"print(dst_cpy)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6db3178a",
			"metadata": {},
			"source": [
				"## rename dimension skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "27a59c5c",
			"metadata": {},
			"source": [
				"## gather from multiple dims"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e8bf17cb",
			"metadata": {},
			"source": [
				"## net training example"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1098,
			"id": "99a743f2",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"Forward hook triggered. Linear(in_features=4, out_features=5, bias=True)\n",
						"loop done.\n"
					]
				}
			],
			"source": [
				"# 168. simple loop again\n",
				"for epoch in range(1):\n",
				"    for i, (bx,by) in enumerate(loader):\n",
				"        bx = bx.half()  # Ensure bx is in half precision\n",
				"        out_ = net_cls(bx)\n",
				"        loss_ = criterion(out_, by)\n",
				"        optim_sgd.zero_grad()\n",
				"        loss_.backward()\n",
				"        optim_sgd.step()\n",
				"print(\"loop done.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "09891c9d",
			"metadata": {},
			"source": [
				"## fiddling with partial usage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1099,
			"id": "a14de496",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([0., 1., 2., 3., 4.]) torch.float32\n"
					]
				}
			],
			"source": [
				"# 169. .type(torch.float)\n",
				"tmp_tt = torch.arange(5).type(torch.float)\n",
				"print(tmp_tt, tmp_tt.dtype)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "0d2309b0",
			"metadata": {},
			"source": [
				"## example of param clone"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1100,
			"id": "67f9ccb4",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([5])\n"
					]
				}
			],
			"source": [
				"# 170. param clone\n",
				"wparam = list(net_cls.parameters())[0]\n",
				"clone_param = wparam.clone()\n",
				"print(clone_param.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "4af014d2",
			"metadata": {},
			"source": [
				"## partial usage of cross platform"
			]
		},
		{
			"cell_type": "markdown",
			"id": "7a66f5fc",
			"metadata": {},
			"source": [
				"## we do 30 more"
			]
		},
		{
			"cell_type": "markdown",
			"id": "3898cc5f",
			"metadata": {},
			"source": [
				"## advanced transforms"
			]
		},
		{
			"cell_type": "markdown",
			"id": "93500dec",
			"metadata": {},
			"source": [
				"## example: to() with dtype and device"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1101,
			"id": "017f8bf1",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.float64 cpu\n"
					]
				}
			],
			"source": [
				"# 171.\n",
				"y_ = torch.randn(2,2).to(dtype=torch.float64, device=device)\n",
				"print(y_.dtype, y_.device)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "cd6845c6",
			"metadata": {},
			"source": [
				"## cat example multiple"
			]
		},
		{
			"cell_type": "markdown",
			"id": "2f5a7b8d",
			"metadata": {},
			"source": [
				"## RNG for normal distribution"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1102,
			"id": "59edca87",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-1.2384, 10.7849])\n"
					]
				}
			],
			"source": [
				"# 172. torch.normal\n",
				"mean_ = torch.tensor([0.0, 10.0])\n",
				"std_ = torch.tensor([1.0, 2.0])\n",
				"norm_ = torch.normal(mean=mean_, std=std_)\n",
				"print(norm_)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "88b664f3",
			"metadata": {},
			"source": [
				"## advanced no usage"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d64d0f39",
			"metadata": {},
			"source": [
				"## coalesce for sparse skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "76e6edf5",
			"metadata": {},
			"source": [
				"## let's do nn.TransformerEncoder, TransformerDecoder"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1103,
			"id": "cbe93f51",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([5, 2, 8])\n"
					]
				}
			],
			"source": [
				"# 173. nn.TransformerEncoder\n",
				"enc_layer = nn.TransformerEncoderLayer(d_model=8, nhead=2)\n",
				"encoder = nn.TransformerEncoder(enc_layer, num_layers=2)\n",
				"inp_enc = torch.randn(5,2,8)\n",
				"enc_out = encoder(inp_enc)\n",
				"print(enc_out.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1104,
			"id": "5c2e0237",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([6, 2, 8])\n"
					]
				}
			],
			"source": [
				"# 174. nn.TransformerDecoder\n",
				"dec_layer = nn.TransformerDecoderLayer(d_model=8, nhead=2)\n",
				"decoder = nn.TransformerDecoder(dec_layer, num_layers=2)\n",
				"tgt_dec = torch.randn(6,2,8)\n",
				"dec_out = decoder(tgt_dec, enc_out)\n",
				"print(dec_out.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "145db6dd",
			"metadata": {},
			"source": [
				"## advanced weighting in ctc skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "bc8e281e",
			"metadata": {},
			"source": [
				"## doc usage skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "bc2eb96d",
			"metadata": {},
			"source": [
				"## HPC apex skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "15ec572d",
			"metadata": {},
			"source": [
				"## 25 more to 200"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1105,
			"id": "d1c5011c",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1., 2., 3.]) torch.float32\n"
					]
				}
			],
			"source": [
				"# 175. from_numpy\n",
				"import numpy as np\n",
				"arr_np2 = np.array([1,2,3], dtype=np.float32)\n",
				"t_from_np = torch.from_numpy(arr_np2)\n",
				"print(t_from_np, t_from_np.dtype)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1106,
			"id": "82bcd5a6",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[1.0, 2.0, 3.0] <class 'list'>\n"
					]
				}
			],
			"source": [
				"# 176. tolist usage\n",
				"python_list = t_from_np.tolist()\n",
				"print(python_list, type(python_list))"
			]
		},
		{
			"cell_type": "markdown",
			"id": "03dc9cf1",
			"metadata": {},
			"source": [
				"## Generator usage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1107,
			"id": "5fc4a571",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-0.1115,  0.1204, -0.3696])\n"
					]
				}
			],
			"source": [
				"# 177. torch.Generator\n",
				"gen_ = torch.Generator().manual_seed(123)\n",
				"rr_ = torch.randn(3, generator=gen_)\n",
				"print(rr_)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "3e056bdf",
			"metadata": {},
			"source": [
				"## advanced AMP autocast"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1108,
			"id": "dd821891",
			"metadata": {},
			"outputs": [],
			"source": [
				"# 178. autocast if available\n",
				"from torch.cuda.amp import autocast, GradScaler\n",
				"\n",
				"if torch.cuda.is_available():\n",
				"    scaler_amp = GradScaler()\n",
				"    with autocast():\n",
				"        out_amp = net_cls(torch.randn(2,4).cuda())\n",
				"    print(\"autocast done.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "3e655d3e",
			"metadata": {},
			"source": [
				"## manual_ seed for cudnn"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1109,
			"id": "46f10706",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"cudnn settings.\n"
					]
				}
			],
			"source": [
				"# 179. torch.backends.cudnn\n",
				"import torch.backends.cudnn as cudnn\n",
				"cudnn.benchmark = True\n",
				"cudnn.deterministic = False\n",
				"print(\"cudnn settings.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "11364654",
			"metadata": {},
			"source": [
				"## global variable skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "59f65070",
			"metadata": {},
			"source": [
				"## functional meltdown"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1110,
			"id": "b33e292d",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 3, 32, 32])\n"
					]
				}
			],
			"source": [
				"# 180. F.interpolate\n",
				"small_im = torch.randn(1,3,16,16)\n",
				"up_im = F.interpolate(small_im, size=(32,32), mode='bilinear')\n",
				"print(up_im.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6d4bd0c8",
			"metadata": {},
			"source": [
				"## replicate usage skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "10cbfd8e",
			"metadata": {},
			"source": [
				"## 19 more to 200"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1111,
			"id": "89df0bcf",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([6])\n"
					]
				}
			],
			"source": [
				"# 181. Flatten (2D to 1D)\n",
				"tt_ = torch.randn(2,3)\n",
				"flat_t = tt_.flatten()\n",
				"print(flat_t.shape)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1112,
			"id": "08885024",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 3])\n"
					]
				}
			],
			"source": [
				"# 182. unflatten\n",
				"unfl_t = flat_t.unflatten(0, (2,3))\n",
				"print(unfl_t.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6fbe39a2",
			"metadata": {},
			"source": [
				"## advanced negative indexing"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1113,
			"id": "19f380ca",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([8, 9])\n"
					]
				}
			],
			"source": [
				"# 183. negative index slice\n",
				"neg_slice = mat[-1, -2:]\n",
				"print(neg_slice)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5205ca09",
			"metadata": {},
			"source": [
				"## rolling not standard"
			]
		},
		{
			"cell_type": "markdown",
			"id": "560fb6ec",
			"metadata": {},
			"source": [
				"## advanced activation: gelu"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1114,
			"id": "4a6c0e41",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-0.1587,  0.0000,  0.8413])\n"
					]
				}
			],
			"source": [
				"# 184. F.gelu\n",
				"vals_gelu = torch.tensor([-1.0,0.0,1.0])\n",
				"out_gelu = F.gelu(vals_gelu)\n",
				"print(out_gelu)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "7d8e99c9",
			"metadata": {},
			"source": [
				"## advanced pooling"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1115,
			"id": "599d8c30",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 3, 16, 16])\n"
					]
				}
			],
			"source": [
				"# 185. nn.AvgPool2d\n",
				"ap2d = nn.AvgPool2d(kernel_size=2)\n",
				"ap_out = ap2d(img_2)\n",
				"print(ap_out.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "92396bc4",
			"metadata": {},
			"source": [
				"## group conv"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1116,
			"id": "bac1f519",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1, 4, 14, 14])\n"
					]
				}
			],
			"source": [
				"# 186. group conv example\n",
				"grp_conv = nn.Conv2d(4,4, kernel_size=3, groups=2)\n",
				"grp_in = torch.randn(1,4,16,16)\n",
				"grp_out = grp_conv(grp_in)\n",
				"print(grp_out.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "655e517e",
			"metadata": {},
			"source": [
				"## CosineAnnealingLR"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1117,
			"id": "7e30ef0a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Ep 0 0.09755282581475769\n",
						"Ep 1 0.09045084971874738\n",
						"Ep 2 0.07938926261462367\n"
					]
				}
			],
			"source": [
				"# 187. CosineAnnealingLR\n",
				"opt_cos = optim.SGD(net_cls.parameters(), lr=0.1)\n",
				"scheduler_cos = optim.lr_scheduler.CosineAnnealingLR(opt_cos, T_max=10)\n",
				"for ep in range(3):\n",
				"    scheduler_cos.step()\n",
				"    print(\"Ep\", ep, opt_cos.param_groups[0]['lr'])"
			]
		},
		{
			"cell_type": "markdown",
			"id": "022dd193",
			"metadata": {},
			"source": [
				"## LBFGS"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1118,
			"id": "8f93cdfd",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"LBFGS (\n",
						"Parameter Group 0\n",
						"    history_size: 100\n",
						"    line_search_fn: None\n",
						"    lr: 0.01\n",
						"    max_eval: 25\n",
						"    max_iter: 20\n",
						"    tolerance_change: 1e-09\n",
						"    tolerance_grad: 1e-07\n",
						")\n"
					]
				}
			],
			"source": [
				"# 188. LBFGS\n",
				"lbfgs_opt = optim.LBFGS(model.parameters(), lr=0.01)\n",
				"print(lbfgs_opt)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d335202b",
			"metadata": {},
			"source": [
				"## AdamW"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1119,
			"id": "bc5f5532",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"AdamW (\n",
						"Parameter Group 0\n",
						"    amsgrad: False\n",
						"    betas: (0.9, 0.999)\n",
						"    capturable: False\n",
						"    differentiable: False\n",
						"    eps: 1e-08\n",
						"    foreach: None\n",
						"    fused: None\n",
						"    lr: 0.001\n",
						"    maximize: False\n",
						"    weight_decay: 0.01\n",
						")\n"
					]
				}
			],
			"source": [
				"# 189. AdamW\n",
				"adamw_opt = optim.AdamW(model.parameters(), lr=0.001)\n",
				"print(adamw_opt)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b5f25459",
			"metadata": {},
			"source": [
				"## multi-labeller skip"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d3e2bc6d",
			"metadata": {},
			"source": [
				"## final 10"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1120,
			"id": "cc4c55fc",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"No error.\n"
					]
				}
			],
			"source": [
				"# 190. detect anomaly again\n",
				"with torch.autograd.set_detect_anomaly(True):\n",
				"    pass\n",
				"print(\"No error.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "7f57cfd8",
			"metadata": {},
			"source": [
				"## find submodule"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1121,
			"id": "67413663",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Linear(in_features=4, out_features=5, bias=True)\n",
						"ReLU()\n",
						"Linear(in_features=5, out_features=2, bias=True)\n"
					]
				}
			],
			"source": [
				"# 191. net.children(), net.named_children()\n",
				"for child in net_cls.children():\n",
				"    print(child)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "2bd298f2",
			"metadata": {},
			"source": [
				"## param grad clamp"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1122,
			"id": "e1afc6d4",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"grad clamp.\n"
					]
				}
			],
			"source": [
				"# 192. for p in model.parameters(): p.grad.data.clamp_(-1,1)\n",
				"for p in net_cls.parameters():\n",
				"    if p.grad is not None:\n",
				"        p.grad.data.clamp_(-1,1)\n",
				"print(\"grad clamp.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "4ec87def",
			"metadata": {},
			"source": [
				"## Adam specific: betas"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1123,
			"id": "3bbf94fa",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Adam (\n",
						"Parameter Group 0\n",
						"    amsgrad: False\n",
						"    betas: (0.9, 0.99)\n",
						"    capturable: False\n",
						"    differentiable: False\n",
						"    eps: 1e-08\n",
						"    foreach: None\n",
						"    fused: None\n",
						"    lr: 0.001\n",
						"    maximize: False\n",
						"    weight_decay: 0\n",
						")\n"
					]
				}
			],
			"source": [
				"# 193. adam with betas\n",
				"adam_b = optim.Adam(model.parameters(), lr=0.001, betas=(0.9,0.99))\n",
				"print(adam_b)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f138256d",
			"metadata": {},
			"source": [
				"## kill ephemeral"
			]
		},
		{
			"cell_type": "markdown",
			"id": "8fc733ab",
			"metadata": {},
			"source": [
				"## replicate final"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1124,
			"id": "046329cd",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1, 2, 3, 4])\n"
					]
				}
			],
			"source": [
				"# 194. torch.unique\n",
				"arr_uniq = torch.tensor([1,2,2,3,3,3,4])\n",
				"unique_vals = torch.unique(arr_uniq)\n",
				"print(unique_vals)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1125,
			"id": "75f65a33",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.return_types.sort(\n",
						"values=tensor([4, 3, 3, 3, 2, 2, 1]),\n",
						"indices=tensor([6, 3, 4, 5, 1, 2, 0]))\n"
					]
				}
			],
			"source": [
				"# 195. torch.sort\n",
				"sorted_res = torch.sort(arr_uniq, descending=True)\n",
				"print(sorted_res)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "15438d5d",
			"metadata": {},
			"source": [
				"## torch.take, put"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1126,
			"id": "5644edc3",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([10, 30])\n"
					]
				}
			],
			"source": [
				"# 196. torch.take\n",
				"vals_take = torch.tensor([[10,20],[30,40]])\n",
				"idx_take = torch.tensor([0,2])\n",
				"taken = torch.take(vals_take, idx_take)\n",
				"print(taken)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1127,
			"id": "de44935b",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[-1, 20],\n",
						"        [-2, 40]])\n"
					]
				}
			],
			"source": [
				"# 197. torch.put_\n",
				"vals_take.put_(idx_take, torch.tensor([-1,-2]))\n",
				"print(vals_take)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "75d33917",
			"metadata": {},
			"source": [
				"## torch.searchsorted"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1128,
			"id": "5af8aaf5",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([1, 3])\n"
					]
				}
			],
			"source": [
				"# 198. torch.searchsorted\n",
				"sorted_arr = torch.tensor([1,3,5,7])\n",
				"vals_ss = torch.tensor([2,6])\n",
				"idx_ss2 = torch.searchsorted(sorted_arr, vals_ss)\n",
				"print(idx_ss2)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "1849ba49",
			"metadata": {},
			"source": [
				"## final 2 cells"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1129,
			"id": "bdd5ba6e",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([ True, False, False,  True])\n",
						"tensor([False,  True, False, False])\n",
						"tensor([False, False,  True, False])\n"
					]
				}
			],
			"source": [
				"# 199. isfinite, isinf, isnan\n",
				"arr_f = torch.tensor([1.0, float('inf'), float('nan'), 2.0])\n",
				"print(torch.isfinite(arr_f))\n",
				"print(torch.isinf(arr_f))\n",
				"print(torch.isnan(arr_f))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1130,
			"id": "7ddaf259",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"All done with top 200.\n"
					]
				}
			],
			"source": [
				"# 200. We've reached 200 PyTorch examples!\n",
				"print(\"All done with top 200.\")"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.9"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 5
}

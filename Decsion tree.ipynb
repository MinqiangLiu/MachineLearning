{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gini_impurity(y):\n",
    "    \"\"\"\n",
    "    计算标签向量 y 的 Gini 不纯度\n",
    "    \n",
    "    :param y: 一维数组 (m,)\n",
    "    :return: Gini 不纯度（标量）\n",
    "    \"\"\"\n",
    "    # 统计每个类别出现的次数\n",
    "    label_counts = {}\n",
    "    for label in y:\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    \n",
    "    m = len(y)  # 样本数\n",
    "    gini = 1.0\n",
    "    for label, count in label_counts.items():\n",
    "        p = count / m  # 该标签在节点中的比例\n",
    "        gini -= p**2   # 累减 p^2\n",
    "\n",
    "    return gini\n",
    "\n",
    "\n",
    "\n",
    "def split_dataset(X, y, feature_idx, threshold):\n",
    "    \"\"\"\n",
    "    根据 feature_idx 列的阈值 threshold 划分数据集\n",
    "    返回: (X_left, y_left, X_right, y_right)\n",
    "    \"\"\"\n",
    "    # 选取该特征列\n",
    "    col_values = X[:, feature_idx]\n",
    "    # 根据阈值进行划分（小于阈值的归左，否则归右）\n",
    "    left_mask = col_values < threshold\n",
    "    right_mask = ~left_mask  # 取反，即大于等于 threshold\n",
    "\n",
    "    X_left, y_left = X[left_mask], y[left_mask]\n",
    "    X_right, y_right = X[right_mask], y[right_mask]\n",
    "    return X_left, y_left, X_right, y_right\n",
    "\n",
    "def best_split(X, y):\n",
    "    \"\"\"\n",
    "    在所有特征的所有可能划分阈值上遍历，\n",
    "    找出能使加权 Gini 不纯度最小的 (best_feature, best_threshold)\n",
    "    同时返回对应划分的数据集 (X_left, y_left, X_right, y_right)\n",
    "    如果无法再划分，则返回 None, None, None, None, None\n",
    "    \n",
    "    注意：这里最简单地把 X[:, feature_idx] 的所有可能取值都当做一个潜在阈值\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    if m <= 1:\n",
    "        return None, None, None, None, None  # 数据太少，无法划分\n",
    "    \n",
    "    # 计算当前节点的 Gini，以便遇到无法找到更好划分时可以短路\n",
    "    current_gini = gini_impurity(y)\n",
    "    best_gain = 0.0\n",
    "    best_feature, best_threshold = None, None\n",
    "    best_splits = (None, None, None, None)\n",
    "    \n",
    "    for feature_idx in range(n):\n",
    "        # 取该列特征的所有值，并去重排序，作为潜在阈值\n",
    "        feature_values = X[:, feature_idx]\n",
    "        unique_values = np.unique(feature_values)\n",
    "        \n",
    "        # 遍历这些唯一值\n",
    "        for threshold in unique_values:\n",
    "            X_left, y_left, X_right, y_right = split_dataset(X, y, feature_idx, threshold)\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                # 如果划分后，有一边为空，则跳过\n",
    "                continue\n",
    "            \n",
    "            # 计算左右子节点的 Gini\n",
    "            gini_left = gini_impurity(y_left)\n",
    "            gini_right = gini_impurity(y_right)\n",
    "            # 加权 Gini（按左右子节点的样本比例）\n",
    "            p_left = len(y_left) / m\n",
    "            p_right = 1.0 - p_left\n",
    "            weighted_gini = p_left * gini_left + p_right * gini_right\n",
    "            \n",
    "            # 信息增益 = current_gini - weighted_gini\n",
    "            gain = current_gini - weighted_gini\n",
    "            \n",
    "            # 找到最优增益\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = threshold\n",
    "                best_splits = (X_left, y_left, X_right, y_right)\n",
    "    \n",
    "    if best_gain > 0:\n",
    "        return best_feature, best_threshold, best_splits[0], best_splits[1], best_splits[2], best_splits[3]\n",
    "    else:\n",
    "        return None, None, None, None, None  # 找不到更好的划分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature_idx=None, threshold=None,\n",
    "                 left_child=None, right_child=None, \n",
    "                 leaf_value=None):\n",
    "        \"\"\"\n",
    "        决策树的节点结构：\n",
    "        :param feature_idx: 划分的特征列索引\n",
    "        :param threshold: 划分阈值\n",
    "        :param left_child: 左子节点\n",
    "        :param right_child: 右子节点\n",
    "        :param leaf_value: 如果是叶节点，存储预测类别\n",
    "        \"\"\"\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.leaf_value = leaf_value\n",
    "\n",
    "def most_common_label(y):\n",
    "    \"\"\"\n",
    "    返回向量 y 中出现频次最高的类别\n",
    "    作为叶节点的输出\n",
    "    \"\"\"\n",
    "    labels, counts = np.unique(y, return_counts=True)\n",
    "    max_count_index = np.argmax(counts)\n",
    "    return labels[max_count_index]\n",
    "\n",
    "class DecisionTreeClassifierScratch:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        \"\"\"\n",
    "        :param max_depth: 决策树最大深度 (None 表示不限制)\n",
    "        :param min_samples_split: 节点最少样本数，小于该值则不再划分\n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        构建决策树\n",
    "        \"\"\"\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"\n",
    "        递归地构建树，返回当前节点\n",
    "        \"\"\"\n",
    "        # 1. 停止条件检查\n",
    "        if len(np.unique(y)) == 1:\n",
    "            # 如果当前节点只有一种类别，直接变成叶节点\n",
    "            leaf_val = y[0]\n",
    "            return DecisionTreeNode(leaf_value=leaf_val)\n",
    "        \n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            # 达到最大深度，返回叶节点\n",
    "            leaf_val = most_common_label(y)\n",
    "            return DecisionTreeNode(leaf_value=leaf_val)\n",
    "        \n",
    "        if len(y) < self.min_samples_split:\n",
    "            # 样本数太少，不再划分\n",
    "            leaf_val = most_common_label(y)\n",
    "            return DecisionTreeNode(leaf_value=leaf_val)\n",
    "        \n",
    "        # 2. 找最优划分\n",
    "        feature_idx, threshold, X_left, y_left, X_right, y_right = best_split(X, y)\n",
    "        \n",
    "        if feature_idx is None:\n",
    "            # 找不到更好的划分\n",
    "            leaf_val = most_common_label(y)\n",
    "            return DecisionTreeNode(leaf_value=leaf_val)\n",
    "        \n",
    "        # 3. 递归构建左右子树\n",
    "        left_child = self._build_tree(X_left, y_left, depth+1)\n",
    "        right_child = self._build_tree(X_right, y_right, depth+1)\n",
    "        \n",
    "        # 4. 返回当前节点\n",
    "        return DecisionTreeNode(feature_idx=feature_idx,\n",
    "                                threshold=threshold,\n",
    "                                left_child=left_child,\n",
    "                                right_child=right_child)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        对于输入 X，每一行做一次预测，输出分类结果\n",
    "        \"\"\"\n",
    "        predictions = [self._predict_sample(sample, self.root) for sample in X]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def _predict_sample(self, x, node):\n",
    "        \"\"\"\n",
    "        从根节点开始，递归地对单条样本 x 进行预测\n",
    "        \"\"\"\n",
    "        # 如果是叶节点，则直接返回叶节点中的类别\n",
    "        if node.leaf_value is not None:\n",
    "            return node.leaf_value\n",
    "        \n",
    "        # 根据当前节点的分割特征和阈值来判断走左还是右\n",
    "        feature_val = x[node.feature_idx]\n",
    "        if feature_val < node.threshold:\n",
    "            return self._predict_sample(x, node.left_child)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right_child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Samples:\n",
      " [[2.5 3. ]\n",
      " [8.  2. ]\n",
      " [3.  2.4]]\n",
      "Predictions: [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 准备一份示例数据\n",
    "    X_train = np.array([\n",
    "        [2.7, 2.5],\n",
    "        [1.3, 1.0],\n",
    "        [3.0, 2.1],\n",
    "        [6.0, 2.3],\n",
    "        [3.0, 3.0],\n",
    "        [7.0, 2.0],\n",
    "        [2.0, 5.0],\n",
    "        [9.0, 1.0],\n",
    "    ])\n",
    "    y_train = np.array([0, 0, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "    # 初始化并训练决策树\n",
    "    tree = DecisionTreeClassifierScratch(max_depth=3, min_samples_split=2)\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # 预测\n",
    "    X_test = np.array([\n",
    "        [2.5, 3.0],\n",
    "        [8.0, 2.0],\n",
    "        [3.0, 2.4],\n",
    "    ])\n",
    "    y_pred = tree.predict(X_test)\n",
    "\n",
    "    # 打印预测结果\n",
    "    print(\"Test Samples:\\n\", X_test)\n",
    "    print(\"Predictions:\", y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
